{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWtltanXrY7F"
      },
      "source": [
        "# MNIST Handwritten Digit Classification Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqNKaRt86ZF-"
      },
      "source": [
        "### Objectives:\n",
        "\n",
        "This notebook performs the following tasks:\n",
        "\n",
        "1. **Data Loading and Preprocessing**:\n",
        "   - Loads the MNIST dataset from OpenML, and previews the first few rows of dataset.\n",
        "   - Splits the dataset into training, validation, and test sets.\n",
        "   - Scales the features using `StandardScaler` to standardize the input data.\n",
        "\n",
        "2. **Neural Network Model Creation**:\n",
        "   - Defines multiple neural network architectures using custom models (`model1`, `model2`, `model3`).\n",
        "   - Configures each model with a varying number of hidden layers and neurons, using ReLU activation for hidden layers and softmax for classification.\n",
        "\n",
        "3. **Model Training**:\n",
        "   - Trains each of the custom neural network models on the scaled training data for 300 epochs.\n",
        "   - Tracks and visualizes the cost (loss) vs iterations during training for all models using Matplotlib.\n",
        "\n",
        "4. **Evaluation of Custom Models**:\n",
        "   - Evaluates the trained models using accuracy and F1 score on the training, validation, and test sets.\n",
        "   - Prints the accuracy and F1 scores for each model on each dataset (train, validation, and test).\n",
        "\n",
        "5. **Building the Optimal Model with TensorFlow**:\n",
        "   - Based on the evaluation of custom models, the best-performing architecture is implemented using TensorFlow’s Keras API (`tf.keras.Sequential`).\n",
        "   - Configures the model with two hidden layers using ReLU activation and a linear output layer.\n",
        "   - Compiles the model with the `SparseCategoricalCrossentropy` loss function and applies softmax internally via the `from_logits=True` argument.\n",
        "\n",
        "6. **Training the TensorFlow Model**:\n",
        "   - Trains the TensorFlow model for 300 epochs on the scaled training data.\n",
        "   - Plots iterations (epochs) vs cost (loss) after training.\n",
        "\n",
        "7. **Prediction and Evaluation on TensorFlow Model**:\n",
        "   - Uses the trained TensorFlow model to predict labels on the training, validation, and test datasets.\n",
        "   - Converts the logits from the linear output layer into probabilities using `tf.nn.softmax()`.\n",
        "   - Uses `argmax` to convert probabilities into class labels.\n",
        "   - Evaluates the model’s performance on all datasets using accuracy and F1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaR9HN22sOjV"
      },
      "source": [
        "### This notebook uses the `MNIST dataset of handwritten digits` to build a neural network model that predicts the correct digit label (0-9).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k798WAiLqgcZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Load the MNIST dataset from OpenML\n",
        "mnist = fetch_openml(\"mnist_784\", version=1)\n",
        "X, y = mnist[\"data\"], mnist[\"target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "fBmByMGJqgck",
        "outputId": "3968ecb9-0349-45bd-dd2d-fc6050eecdec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3db86313-f74b-4496-a920-437c1f38e863\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3db86313-f74b-4496-a920-437c1f38e863')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3db86313-f74b-4496-a920-437c1f38e863 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3db86313-f74b-4496-a920-437c1f38e863');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fb3614be-7dae-4ccb-adb1-2b6d02278872\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb3614be-7dae-4ccb-adb1-2b6d02278872')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fb3614be-7dae-4ccb-adb1-2b6d02278872 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              "0       0       0       0       0       0       0       0       0       0   \n",
              "1       0       0       0       0       0       0       0       0       0   \n",
              "2       0       0       0       0       0       0       0       0       0   \n",
              "3       0       0       0       0       0       0       0       0       0   \n",
              "4       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0        0  ...         0         0         0         0         0         0   \n",
              "1        0  ...         0         0         0         0         0         0   \n",
              "2        0  ...         0         0         0         0         0         0   \n",
              "3        0  ...         0         0         0         0         0         0   \n",
              "4        0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2         0         0         0         0  \n",
              "3         0         0         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview the first few rows of features (X)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "DXc1dBOMqgcn",
        "outputId": "68d56b6f-6ae2-4428-859a-bfb5bde18247"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> category</label>"
            ],
            "text/plain": [
              "0    5\n",
              "1    0\n",
              "2    4\n",
              "3    1\n",
              "4    9\n",
              "Name: class, dtype: category\n",
              "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview the first few rows of labels (y)\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t82HY9Tiqgcp",
        "outputId": "4dd57841-635f-4c44-e68d-9ab6f449c575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shape: (34300, 784) (34300, 1)\n",
            "Validation set shape: (14700, 784) (14700, 1)\n",
            "Testing set shape: (21000, 784) (21000, 1)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Convert X and y to numpy arrays for further processing\n",
        "X = X.values\n",
        "Y = y.values.astype(int).reshape(-1, 1)\n",
        "\n",
        "# First split: Train + Validation and Test sets (70% for training/validation, 30% for test)\n",
        "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)\n",
        "\n",
        "# Second split: Training and Validation sets (70% of train_val data for training, 30% for validation)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=0.3, random_state=42, stratify=Y_train_val)\n",
        "\n",
        "# Output the shapes of the data splits for verification\n",
        "print(\"Training set shape:\", X_train.shape, Y_train.shape)\n",
        "print(\"Validation set shape:\", X_val.shape, Y_val.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PfCNxstVqgcs"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the StandardScaler to scale the feature data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform it (normalization/standardization)\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Use the same scaler to transform the validation and test data (same scaling for consistency)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rS3WPrmyqgcu"
      },
      "outputs": [],
      "source": [
        "import nn_base\n",
        "\n",
        "# Custom neural network models (these are hypothetical models defined in nn_base)\n",
        "model1 = nn_base.NeuralNetworkModel()\n",
        "model2 = nn_base.NeuralNetworkModel()\n",
        "model3 = nn_base.NeuralNetworkModel()\n",
        "\n",
        "# Define model1 architecture with 1 hidden layer (20 units) and output layer with softmax\n",
        "model1.sequential([\n",
        "    model1.layer(units=20, activation=\"relu\"),\n",
        "    model1.layer(units=10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "# Define model2 architecture with 2 hidden layers (30, 20 units) and output layer with softmax\n",
        "model2.sequential([\n",
        "    model2.layer(units=30, activation=\"relu\"),\n",
        "    model2.layer(units=20, activation=\"relu\"),\n",
        "    model2.layer(units=10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "# Define model3 architecture with 3 hidden layers (40, 30, 20 units) and output layer with softmax\n",
        "model3.sequential([\n",
        "    model3.layer(units=40, activation=\"relu\"),\n",
        "    model3.layer(units=30, activation=\"relu\"),\n",
        "    model3.layer(units=20, activation=\"relu\"),\n",
        "    model3.layer(units=10, activation=\"softmax\"),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAjixlSJqgcw",
        "outputId": "fec6f6d3-2e92-4309-c959-36d7c415e160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Model_1:\n",
            "\n",
            "Epoch: 1/300\n",
            "cost = 2.97345239824084\n",
            "Epoch: 2/300\n",
            "cost = 1.8536538985449977\n",
            "Epoch: 3/300\n",
            "cost = 1.2600458003536945\n",
            "Epoch: 4/300\n",
            "cost = 0.9488917158383492\n",
            "Epoch: 5/300\n",
            "cost = 0.7437500294930687\n",
            "Epoch: 6/300\n",
            "cost = 0.7020029959414847\n",
            "Epoch: 7/300\n",
            "cost = 0.6467485064598401\n",
            "Epoch: 8/300\n",
            "cost = 0.6077898211599667\n",
            "Epoch: 9/300\n",
            "cost = 0.576577144860016\n",
            "Epoch: 10/300\n",
            "cost = 0.5364610783208695\n",
            "Epoch: 11/300\n",
            "cost = 0.531978021533619\n",
            "Epoch: 12/300\n",
            "cost = 0.5079322016903614\n",
            "Epoch: 13/300\n",
            "cost = 0.4690141913403598\n",
            "Epoch: 14/300\n",
            "cost = 0.4513103134570487\n",
            "Epoch: 15/300\n",
            "cost = 0.41717358002216126\n",
            "Epoch: 16/300\n",
            "cost = 0.40784837464527973\n",
            "Epoch: 17/300\n",
            "cost = 0.3984222333109937\n",
            "Epoch: 18/300\n",
            "cost = 0.3823347830484216\n",
            "Epoch: 19/300\n",
            "cost = 0.3735335178728339\n",
            "Epoch: 20/300\n",
            "cost = 0.35966438100697357\n",
            "Epoch: 21/300\n",
            "cost = 0.33317655275023117\n",
            "Epoch: 22/300\n",
            "cost = 0.3215301724705224\n",
            "Epoch: 23/300\n",
            "cost = 0.30872640249696337\n",
            "Epoch: 24/300\n",
            "cost = 0.29479342675325676\n",
            "Epoch: 25/300\n",
            "cost = 0.2877292637619226\n",
            "Epoch: 26/300\n",
            "cost = 0.278359525878503\n",
            "Epoch: 27/300\n",
            "cost = 0.2724636438609235\n",
            "Epoch: 28/300\n",
            "cost = 0.26630781185370245\n",
            "Epoch: 29/300\n",
            "cost = 0.25922465987227883\n",
            "Epoch: 30/300\n",
            "cost = 0.25562142371647856\n",
            "Epoch: 31/300\n",
            "cost = 0.24793795822917827\n",
            "Epoch: 32/300\n",
            "cost = 0.24067657788040214\n",
            "Epoch: 33/300\n",
            "cost = 0.23694910580011147\n",
            "Epoch: 34/300\n",
            "cost = 0.23166163137951837\n",
            "Epoch: 35/300\n",
            "cost = 0.2281554534116693\n",
            "Epoch: 36/300\n",
            "cost = 0.22346220950811624\n",
            "Epoch: 37/300\n",
            "cost = 0.2194802215081314\n",
            "Epoch: 38/300\n",
            "cost = 0.21572013301611564\n",
            "Epoch: 39/300\n",
            "cost = 0.2128422517661495\n",
            "Epoch: 40/300\n",
            "cost = 0.20987785401087256\n",
            "Epoch: 41/300\n",
            "cost = 0.20696248604683118\n",
            "Epoch: 42/300\n",
            "cost = 0.2040850246668963\n",
            "Epoch: 43/300\n",
            "cost = 0.20107880822973373\n",
            "Epoch: 44/300\n",
            "cost = 0.19912628180793954\n",
            "Epoch: 45/300\n",
            "cost = 0.1965847324009744\n",
            "Epoch: 46/300\n",
            "cost = 0.19420015512205158\n",
            "Epoch: 47/300\n",
            "cost = 0.19240246767068572\n",
            "Epoch: 48/300\n",
            "cost = 0.1901167822750282\n",
            "Epoch: 49/300\n",
            "cost = 0.18860749238670055\n",
            "Epoch: 50/300\n",
            "cost = 0.1865312793946657\n",
            "Epoch: 51/300\n",
            "cost = 0.184644006368324\n",
            "Epoch: 52/300\n",
            "cost = 0.18302510861347504\n",
            "Epoch: 53/300\n",
            "cost = 0.18127982609124293\n",
            "Epoch: 54/300\n",
            "cost = 0.17998099490500064\n",
            "Epoch: 55/300\n",
            "cost = 0.17842655026505458\n",
            "Epoch: 56/300\n",
            "cost = 0.17672900807383485\n",
            "Epoch: 57/300\n",
            "cost = 0.17531979411142287\n",
            "Epoch: 58/300\n",
            "cost = 0.17392094947526318\n",
            "Epoch: 59/300\n",
            "cost = 0.17266635284179085\n",
            "Epoch: 60/300\n",
            "cost = 0.17135152417676602\n",
            "Epoch: 61/300\n",
            "cost = 0.17000954335793042\n",
            "Epoch: 62/300\n",
            "cost = 0.1689000335732897\n",
            "Epoch: 63/300\n",
            "cost = 0.16777879523132969\n",
            "Epoch: 64/300\n",
            "cost = 0.1667289310877563\n",
            "Epoch: 65/300\n",
            "cost = 0.16564437438074525\n",
            "Epoch: 66/300\n",
            "cost = 0.16452103055592307\n",
            "Epoch: 67/300\n",
            "cost = 0.16344939977153566\n",
            "Epoch: 68/300\n",
            "cost = 0.16239973629599505\n",
            "Epoch: 69/300\n",
            "cost = 0.16140548836900462\n",
            "Epoch: 70/300\n",
            "cost = 0.16046142514600487\n",
            "Epoch: 71/300\n",
            "cost = 0.15947903061949703\n",
            "Epoch: 72/300\n",
            "cost = 0.15853793536655156\n",
            "Epoch: 73/300\n",
            "cost = 0.15761025043409316\n",
            "Epoch: 74/300\n",
            "cost = 0.15671753947570838\n",
            "Epoch: 75/300\n",
            "cost = 0.15584979699055487\n",
            "Epoch: 76/300\n",
            "cost = 0.15497000457933177\n",
            "Epoch: 77/300\n",
            "cost = 0.15409891659359495\n",
            "Epoch: 78/300\n",
            "cost = 0.15324923940326385\n",
            "Epoch: 79/300\n",
            "cost = 0.15240982630379604\n",
            "Epoch: 80/300\n",
            "cost = 0.15160363960277584\n",
            "Epoch: 81/300\n",
            "cost = 0.15079256749601194\n",
            "Epoch: 82/300\n",
            "cost = 0.14998533746871995\n",
            "Epoch: 83/300\n",
            "cost = 0.14919713632811493\n",
            "Epoch: 84/300\n",
            "cost = 0.1484177657636681\n",
            "Epoch: 85/300\n",
            "cost = 0.14765129650224632\n",
            "Epoch: 86/300\n",
            "cost = 0.1468960463838957\n",
            "Epoch: 87/300\n",
            "cost = 0.146134445348065\n",
            "Epoch: 88/300\n",
            "cost = 0.14538913730412859\n",
            "Epoch: 89/300\n",
            "cost = 0.144654669221181\n",
            "Epoch: 90/300\n",
            "cost = 0.1439246541578986\n",
            "Epoch: 91/300\n",
            "cost = 0.14320856848251556\n",
            "Epoch: 92/300\n",
            "cost = 0.14250034907368653\n",
            "Epoch: 93/300\n",
            "cost = 0.14179535396409124\n",
            "Epoch: 94/300\n",
            "cost = 0.14110232409691148\n",
            "Epoch: 95/300\n",
            "cost = 0.14041673041021913\n",
            "Epoch: 96/300\n",
            "cost = 0.13973729071164676\n",
            "Epoch: 97/300\n",
            "cost = 0.13906872292917657\n",
            "Epoch: 98/300\n",
            "cost = 0.13840615347478444\n",
            "Epoch: 99/300\n",
            "cost = 0.1377504175653344\n",
            "Epoch: 100/300\n",
            "cost = 0.13710104628977718\n",
            "Epoch: 101/300\n",
            "cost = 0.1364573896100715\n",
            "Epoch: 102/300\n",
            "cost = 0.1358181824523506\n",
            "Epoch: 103/300\n",
            "cost = 0.1351843090275241\n",
            "Epoch: 104/300\n",
            "cost = 0.13455325231525697\n",
            "Epoch: 105/300\n",
            "cost = 0.13392876680603372\n",
            "Epoch: 106/300\n",
            "cost = 0.1333097172611738\n",
            "Epoch: 107/300\n",
            "cost = 0.1326970016241377\n",
            "Epoch: 108/300\n",
            "cost = 0.13208992039996045\n",
            "Epoch: 109/300\n",
            "cost = 0.1314871285269233\n",
            "Epoch: 110/300\n",
            "cost = 0.13089137604037177\n",
            "Epoch: 111/300\n",
            "cost = 0.13030074817182993\n",
            "Epoch: 112/300\n",
            "cost = 0.12971384314268095\n",
            "Epoch: 113/300\n",
            "cost = 0.1291311229202904\n",
            "Epoch: 114/300\n",
            "cost = 0.12855453258806307\n",
            "Epoch: 115/300\n",
            "cost = 0.1279819961201751\n",
            "Epoch: 116/300\n",
            "cost = 0.1274122967238462\n",
            "Epoch: 117/300\n",
            "cost = 0.1268473801096008\n",
            "Epoch: 118/300\n",
            "cost = 0.12628629895413554\n",
            "Epoch: 119/300\n",
            "cost = 0.12573050197276053\n",
            "Epoch: 120/300\n",
            "cost = 0.12517823624210161\n",
            "Epoch: 121/300\n",
            "cost = 0.12462953848068233\n",
            "Epoch: 122/300\n",
            "cost = 0.1240853357475693\n",
            "Epoch: 123/300\n",
            "cost = 0.1235462833437013\n",
            "Epoch: 124/300\n",
            "cost = 0.12301281452933112\n",
            "Epoch: 125/300\n",
            "cost = 0.12248302089179389\n",
            "Epoch: 126/300\n",
            "cost = 0.12195819938954842\n",
            "Epoch: 127/300\n",
            "cost = 0.12143935767531398\n",
            "Epoch: 128/300\n",
            "cost = 0.12092435521773866\n",
            "Epoch: 129/300\n",
            "cost = 0.12041248262724565\n",
            "Epoch: 130/300\n",
            "cost = 0.11990560749461639\n",
            "Epoch: 131/300\n",
            "cost = 0.11940316447611456\n",
            "Epoch: 132/300\n",
            "cost = 0.11890540034485646\n",
            "Epoch: 133/300\n",
            "cost = 0.11841148114781744\n",
            "Epoch: 134/300\n",
            "cost = 0.11791990606500444\n",
            "Epoch: 135/300\n",
            "cost = 0.11743218669362081\n",
            "Epoch: 136/300\n",
            "cost = 0.11694767676738277\n",
            "Epoch: 137/300\n",
            "cost = 0.11646682325520459\n",
            "Epoch: 138/300\n",
            "cost = 0.11598908159946346\n",
            "Epoch: 139/300\n",
            "cost = 0.11551461913756236\n",
            "Epoch: 140/300\n",
            "cost = 0.11504399331495097\n",
            "Epoch: 141/300\n",
            "cost = 0.11457623165813577\n",
            "Epoch: 142/300\n",
            "cost = 0.11411112690007354\n",
            "Epoch: 143/300\n",
            "cost = 0.11364960727643254\n",
            "Epoch: 144/300\n",
            "cost = 0.11319235376526285\n",
            "Epoch: 145/300\n",
            "cost = 0.11273932640718681\n",
            "Epoch: 146/300\n",
            "cost = 0.11228876009278002\n",
            "Epoch: 147/300\n",
            "cost = 0.11184221191297745\n",
            "Epoch: 148/300\n",
            "cost = 0.11139954841979825\n",
            "Epoch: 149/300\n",
            "cost = 0.11096034291493753\n",
            "Epoch: 150/300\n",
            "cost = 0.11052460785844392\n",
            "Epoch: 151/300\n",
            "cost = 0.11009219912597105\n",
            "Epoch: 152/300\n",
            "cost = 0.10966317877355361\n",
            "Epoch: 153/300\n",
            "cost = 0.1092363225377574\n",
            "Epoch: 154/300\n",
            "cost = 0.1088125416801818\n",
            "Epoch: 155/300\n",
            "cost = 0.10839053389225958\n",
            "Epoch: 156/300\n",
            "cost = 0.10796986816430144\n",
            "Epoch: 157/300\n",
            "cost = 0.10755054361738417\n",
            "Epoch: 158/300\n",
            "cost = 0.1071339125144529\n",
            "Epoch: 159/300\n",
            "cost = 0.10671932493377938\n",
            "Epoch: 160/300\n",
            "cost = 0.10630669582595062\n",
            "Epoch: 161/300\n",
            "cost = 0.10589586176695566\n",
            "Epoch: 162/300\n",
            "cost = 0.10548754341214855\n",
            "Epoch: 163/300\n",
            "cost = 0.10508047471643753\n",
            "Epoch: 164/300\n",
            "cost = 0.10467570817104985\n",
            "Epoch: 165/300\n",
            "cost = 0.1042737640466701\n",
            "Epoch: 166/300\n",
            "cost = 0.10387395891487361\n",
            "Epoch: 167/300\n",
            "cost = 0.10347584322030129\n",
            "Epoch: 168/300\n",
            "cost = 0.10308004100955806\n",
            "Epoch: 169/300\n",
            "cost = 0.10268708757922204\n",
            "Epoch: 170/300\n",
            "cost = 0.10229626280225085\n",
            "Epoch: 171/300\n",
            "cost = 0.10190766139657047\n",
            "Epoch: 172/300\n",
            "cost = 0.1015224245300661\n",
            "Epoch: 173/300\n",
            "cost = 0.10114046122473076\n",
            "Epoch: 174/300\n",
            "cost = 0.10076029314998067\n",
            "Epoch: 175/300\n",
            "cost = 0.10038278085192316\n",
            "Epoch: 176/300\n",
            "cost = 0.10000776774801207\n",
            "Epoch: 177/300\n",
            "cost = 0.09963540505254423\n",
            "Epoch: 178/300\n",
            "cost = 0.09926560489252535\n",
            "Epoch: 179/300\n",
            "cost = 0.09889805551749589\n",
            "Epoch: 180/300\n",
            "cost = 0.09853205654382308\n",
            "Epoch: 181/300\n",
            "cost = 0.09816708081918618\n",
            "Epoch: 182/300\n",
            "cost = 0.09780283204818382\n",
            "Epoch: 183/300\n",
            "cost = 0.0974409017003686\n",
            "Epoch: 184/300\n",
            "cost = 0.09708100946764436\n",
            "Epoch: 185/300\n",
            "cost = 0.09672312139409762\n",
            "Epoch: 186/300\n",
            "cost = 0.0963673212455901\n",
            "Epoch: 187/300\n",
            "cost = 0.0960132973362571\n",
            "Epoch: 188/300\n",
            "cost = 0.09566041564822587\n",
            "Epoch: 189/300\n",
            "cost = 0.09530956431439687\n",
            "Epoch: 190/300\n",
            "cost = 0.09496076955921016\n",
            "Epoch: 191/300\n",
            "cost = 0.09461331883690749\n",
            "Epoch: 192/300\n",
            "cost = 0.09426734181360108\n",
            "Epoch: 193/300\n",
            "cost = 0.09392311886590861\n",
            "Epoch: 194/300\n",
            "cost = 0.09358056213157134\n",
            "Epoch: 195/300\n",
            "cost = 0.09324059933884024\n",
            "Epoch: 196/300\n",
            "cost = 0.09290298165946842\n",
            "Epoch: 197/300\n",
            "cost = 0.092567442257733\n",
            "Epoch: 198/300\n",
            "cost = 0.09223326410732766\n",
            "Epoch: 199/300\n",
            "cost = 0.09190134813451106\n",
            "Epoch: 200/300\n",
            "cost = 0.09157199486990526\n",
            "Epoch: 201/300\n",
            "cost = 0.09124507221266101\n",
            "Epoch: 202/300\n",
            "cost = 0.09092022740437311\n",
            "Epoch: 203/300\n",
            "cost = 0.090598027449626\n",
            "Epoch: 204/300\n",
            "cost = 0.09027785164997575\n",
            "Epoch: 205/300\n",
            "cost = 0.08995887775307831\n",
            "Epoch: 206/300\n",
            "cost = 0.08963942844648717\n",
            "Epoch: 207/300\n",
            "cost = 0.08932159046416775\n",
            "Epoch: 208/300\n",
            "cost = 0.08900498907465414\n",
            "Epoch: 209/300\n",
            "cost = 0.08868945303937796\n",
            "Epoch: 210/300\n",
            "cost = 0.08837601369970165\n",
            "Epoch: 211/300\n",
            "cost = 0.08806400860148265\n",
            "Epoch: 212/300\n",
            "cost = 0.0877542949683537\n",
            "Epoch: 213/300\n",
            "cost = 0.08744724886520851\n",
            "Epoch: 214/300\n",
            "cost = 0.08714140817593671\n",
            "Epoch: 215/300\n",
            "cost = 0.08683738270231649\n",
            "Epoch: 216/300\n",
            "cost = 0.08653575818528023\n",
            "Epoch: 217/300\n",
            "cost = 0.08623583694342617\n",
            "Epoch: 218/300\n",
            "cost = 0.08593722618791265\n",
            "Epoch: 219/300\n",
            "cost = 0.08563995704436778\n",
            "Epoch: 220/300\n",
            "cost = 0.08534396689325983\n",
            "Epoch: 221/300\n",
            "cost = 0.08504888173634804\n",
            "Epoch: 222/300\n",
            "cost = 0.08475514002244823\n",
            "Epoch: 223/300\n",
            "cost = 0.08446318229407057\n",
            "Epoch: 224/300\n",
            "cost = 0.08417321436655796\n",
            "Epoch: 225/300\n",
            "cost = 0.08388511167361047\n",
            "Epoch: 226/300\n",
            "cost = 0.083597966832614\n",
            "Epoch: 227/300\n",
            "cost = 0.08331186364228056\n",
            "Epoch: 228/300\n",
            "cost = 0.08302645587250153\n",
            "Epoch: 229/300\n",
            "cost = 0.08274252360171602\n",
            "Epoch: 230/300\n",
            "cost = 0.0824605090399829\n",
            "Epoch: 231/300\n",
            "cost = 0.08217932059787957\n",
            "Epoch: 232/300\n",
            "cost = 0.08189905713663127\n",
            "Epoch: 233/300\n",
            "cost = 0.08162043017206373\n",
            "Epoch: 234/300\n",
            "cost = 0.08134271912130087\n",
            "Epoch: 235/300\n",
            "cost = 0.08106613099113703\n",
            "Epoch: 236/300\n",
            "cost = 0.08079144649139731\n",
            "Epoch: 237/300\n",
            "cost = 0.08051842053718246\n",
            "Epoch: 238/300\n",
            "cost = 0.08024584967539558\n",
            "Epoch: 239/300\n",
            "cost = 0.07997464234166357\n",
            "Epoch: 240/300\n",
            "cost = 0.07970480408219867\n",
            "Epoch: 241/300\n",
            "cost = 0.07943634271393848\n",
            "Epoch: 242/300\n",
            "cost = 0.07916930137936214\n",
            "Epoch: 243/300\n",
            "cost = 0.07890393346944184\n",
            "Epoch: 244/300\n",
            "cost = 0.07863918548160004\n",
            "Epoch: 245/300\n",
            "cost = 0.07837544588740138\n",
            "Epoch: 246/300\n",
            "cost = 0.07811313072316807\n",
            "Epoch: 247/300\n",
            "cost = 0.07785193997744494\n",
            "Epoch: 248/300\n",
            "cost = 0.07759237756812981\n",
            "Epoch: 249/300\n",
            "cost = 0.07733423350737909\n",
            "Epoch: 250/300\n",
            "cost = 0.07707651283149872\n",
            "Epoch: 251/300\n",
            "cost = 0.07681998182809742\n",
            "Epoch: 252/300\n",
            "cost = 0.07656422184855954\n",
            "Epoch: 253/300\n",
            "cost = 0.07631009137854634\n",
            "Epoch: 254/300\n",
            "cost = 0.07605757713348886\n",
            "Epoch: 255/300\n",
            "cost = 0.07580623882744608\n",
            "Epoch: 256/300\n",
            "cost = 0.07555615858021823\n",
            "Epoch: 257/300\n",
            "cost = 0.07530671556985524\n",
            "Epoch: 258/300\n",
            "cost = 0.0750586926938424\n",
            "Epoch: 259/300\n",
            "cost = 0.0748127183882509\n",
            "Epoch: 260/300\n",
            "cost = 0.07456766284272426\n",
            "Epoch: 261/300\n",
            "cost = 0.07432369373744098\n",
            "Epoch: 262/300\n",
            "cost = 0.07408060838477452\n",
            "Epoch: 263/300\n",
            "cost = 0.07383798247853873\n",
            "Epoch: 264/300\n",
            "cost = 0.07359580901801904\n",
            "Epoch: 265/300\n",
            "cost = 0.07335392912109835\n",
            "Epoch: 266/300\n",
            "cost = 0.07311301536952812\n",
            "Epoch: 267/300\n",
            "cost = 0.07287143374714947\n",
            "Epoch: 268/300\n",
            "cost = 0.07263034959088435\n",
            "Epoch: 269/300\n",
            "cost = 0.07239015987730854\n",
            "Epoch: 270/300\n",
            "cost = 0.0721502337563444\n",
            "Epoch: 271/300\n",
            "cost = 0.07191093818791935\n",
            "Epoch: 272/300\n",
            "cost = 0.0716725962194549\n",
            "Epoch: 273/300\n",
            "cost = 0.07143530141454635\n",
            "Epoch: 274/300\n",
            "cost = 0.07119909737359083\n",
            "Epoch: 275/300\n",
            "cost = 0.07096417152806611\n",
            "Epoch: 276/300\n",
            "cost = 0.07072999832786893\n",
            "Epoch: 277/300\n",
            "cost = 0.07049613006887404\n",
            "Epoch: 278/300\n",
            "cost = 0.07026303604015322\n",
            "Epoch: 279/300\n",
            "cost = 0.07003076183152974\n",
            "Epoch: 280/300\n",
            "cost = 0.06979944198025444\n",
            "Epoch: 281/300\n",
            "cost = 0.06956848748663727\n",
            "Epoch: 282/300\n",
            "cost = 0.069338545922976\n",
            "Epoch: 283/300\n",
            "cost = 0.0691098850158824\n",
            "Epoch: 284/300\n",
            "cost = 0.06888190357368323\n",
            "Epoch: 285/300\n",
            "cost = 0.06865492984748518\n",
            "Epoch: 286/300\n",
            "cost = 0.06842934783092249\n",
            "Epoch: 287/300\n",
            "cost = 0.06820467759089056\n",
            "Epoch: 288/300\n",
            "cost = 0.06798095871100651\n",
            "Epoch: 289/300\n",
            "cost = 0.06775808765949426\n",
            "Epoch: 290/300\n",
            "cost = 0.06753712209770463\n",
            "Epoch: 291/300\n",
            "cost = 0.06731665713631468\n",
            "Epoch: 292/300\n",
            "cost = 0.06709727476703398\n",
            "Epoch: 293/300\n",
            "cost = 0.06687809745777426\n",
            "Epoch: 294/300\n",
            "cost = 0.06665986621187843\n",
            "Epoch: 295/300\n",
            "cost = 0.06644298475458392\n",
            "Epoch: 296/300\n",
            "cost = 0.0662267893962421\n",
            "Epoch: 297/300\n",
            "cost = 0.0660113588042762\n",
            "Epoch: 298/300\n",
            "cost = 0.0657969635684949\n",
            "Epoch: 299/300\n",
            "cost = 0.06558360746364994\n",
            "Epoch: 300/300\n",
            "cost = 0.065371645303253\n",
            "\n",
            "Training Model_2:\n",
            "\n",
            "Epoch: 1/300\n",
            "cost = 2.6552281578155355\n",
            "Epoch: 2/300\n",
            "cost = 2.1237758721377777\n",
            "Epoch: 3/300\n",
            "cost = 1.753341634423462\n",
            "Epoch: 4/300\n",
            "cost = 1.43358199207254\n",
            "Epoch: 5/300\n",
            "cost = 1.1384541418385048\n",
            "Epoch: 6/300\n",
            "cost = 0.9184992537990045\n",
            "Epoch: 7/300\n",
            "cost = 0.7959310658595166\n",
            "Epoch: 8/300\n",
            "cost = 0.6919877835977867\n",
            "Epoch: 9/300\n",
            "cost = 0.652183569536921\n",
            "Epoch: 10/300\n",
            "cost = 0.6389824785635905\n",
            "Epoch: 11/300\n",
            "cost = 0.6594091582770345\n",
            "Epoch: 12/300\n",
            "cost = 0.7187290841671855\n",
            "Epoch: 13/300\n",
            "cost = 0.530188096579222\n",
            "Epoch: 14/300\n",
            "cost = 0.5243947790880461\n",
            "Epoch: 15/300\n",
            "cost = 0.4717313748402576\n",
            "Epoch: 16/300\n",
            "cost = 0.4614471914828985\n",
            "Epoch: 17/300\n",
            "cost = 0.3941985045030836\n",
            "Epoch: 18/300\n",
            "cost = 0.40607913170597454\n",
            "Epoch: 19/300\n",
            "cost = 0.3718723503624198\n",
            "Epoch: 20/300\n",
            "cost = 0.34855631997998066\n",
            "Epoch: 21/300\n",
            "cost = 0.3523865751023017\n",
            "Epoch: 22/300\n",
            "cost = 0.32753198204028755\n",
            "Epoch: 23/300\n",
            "cost = 0.31143085038646756\n",
            "Epoch: 24/300\n",
            "cost = 0.30743641142612105\n",
            "Epoch: 25/300\n",
            "cost = 0.2883990355292317\n",
            "Epoch: 26/300\n",
            "cost = 0.27686835253437825\n",
            "Epoch: 27/300\n",
            "cost = 0.27561975765314434\n",
            "Epoch: 28/300\n",
            "cost = 0.2643286835522629\n",
            "Epoch: 29/300\n",
            "cost = 0.24986087650367908\n",
            "Epoch: 30/300\n",
            "cost = 0.24577410481452805\n",
            "Epoch: 31/300\n",
            "cost = 0.2413115287165276\n",
            "Epoch: 32/300\n",
            "cost = 0.2324437692458496\n",
            "Epoch: 33/300\n",
            "cost = 0.22732797906133234\n",
            "Epoch: 34/300\n",
            "cost = 0.22134734678558415\n",
            "Epoch: 35/300\n",
            "cost = 0.21398626314679012\n",
            "Epoch: 36/300\n",
            "cost = 0.2102952100504123\n",
            "Epoch: 37/300\n",
            "cost = 0.20605157659041629\n",
            "Epoch: 38/300\n",
            "cost = 0.19945634275383087\n",
            "Epoch: 39/300\n",
            "cost = 0.19574788629239323\n",
            "Epoch: 40/300\n",
            "cost = 0.1926888425298801\n",
            "Epoch: 41/300\n",
            "cost = 0.188080520094259\n",
            "Epoch: 42/300\n",
            "cost = 0.18456772649072198\n",
            "Epoch: 43/300\n",
            "cost = 0.18178854695850122\n",
            "Epoch: 44/300\n",
            "cost = 0.17763316974461502\n",
            "Epoch: 45/300\n",
            "cost = 0.17395412559988593\n",
            "Epoch: 46/300\n",
            "cost = 0.17156867394094272\n",
            "Epoch: 47/300\n",
            "cost = 0.16853587836390924\n",
            "Epoch: 48/300\n",
            "cost = 0.16533185359380784\n",
            "Epoch: 49/300\n",
            "cost = 0.16330131362846534\n",
            "Epoch: 50/300\n",
            "cost = 0.16116530258703005\n",
            "Epoch: 51/300\n",
            "cost = 0.15847949981490736\n",
            "Epoch: 52/300\n",
            "cost = 0.15649904285363045\n",
            "Epoch: 53/300\n",
            "cost = 0.15465379992141398\n",
            "Epoch: 54/300\n",
            "cost = 0.15222956044316313\n",
            "Epoch: 55/300\n",
            "cost = 0.15016484981688644\n",
            "Epoch: 56/300\n",
            "cost = 0.14850721205069314\n",
            "Epoch: 57/300\n",
            "cost = 0.14649265715819113\n",
            "Epoch: 58/300\n",
            "cost = 0.1445518885267278\n",
            "Epoch: 59/300\n",
            "cost = 0.14296583142360825\n",
            "Epoch: 60/300\n",
            "cost = 0.14123456207806476\n",
            "Epoch: 61/300\n",
            "cost = 0.13952585915117\n",
            "Epoch: 62/300\n",
            "cost = 0.138116701958874\n",
            "Epoch: 63/300\n",
            "cost = 0.13659893694204808\n",
            "Epoch: 64/300\n",
            "cost = 0.13494538372857404\n",
            "Epoch: 65/300\n",
            "cost = 0.13354421836901778\n",
            "Epoch: 66/300\n",
            "cost = 0.13220528303495382\n",
            "Epoch: 67/300\n",
            "cost = 0.13070938216527175\n",
            "Epoch: 68/300\n",
            "cost = 0.12931936496432084\n",
            "Epoch: 69/300\n",
            "cost = 0.12807357544545642\n",
            "Epoch: 70/300\n",
            "cost = 0.1267567422071699\n",
            "Epoch: 71/300\n",
            "cost = 0.12545617874176154\n",
            "Epoch: 72/300\n",
            "cost = 0.12423956426987197\n",
            "Epoch: 73/300\n",
            "cost = 0.1229769484493167\n",
            "Epoch: 74/300\n",
            "cost = 0.1217208066196193\n",
            "Epoch: 75/300\n",
            "cost = 0.12055604062286845\n",
            "Epoch: 76/300\n",
            "cost = 0.11938669524407697\n",
            "Epoch: 77/300\n",
            "cost = 0.11819420061830364\n",
            "Epoch: 78/300\n",
            "cost = 0.11706129575412255\n",
            "Epoch: 79/300\n",
            "cost = 0.11596281248112261\n",
            "Epoch: 80/300\n",
            "cost = 0.11484195754565449\n",
            "Epoch: 81/300\n",
            "cost = 0.11374536958412995\n",
            "Epoch: 82/300\n",
            "cost = 0.11268725760076377\n",
            "Epoch: 83/300\n",
            "cost = 0.1116237582642187\n",
            "Epoch: 84/300\n",
            "cost = 0.11058273186276334\n",
            "Epoch: 85/300\n",
            "cost = 0.10957604257600555\n",
            "Epoch: 86/300\n",
            "cost = 0.10856882035834736\n",
            "Epoch: 87/300\n",
            "cost = 0.10756692382727899\n",
            "Epoch: 88/300\n",
            "cost = 0.10659544243214691\n",
            "Epoch: 89/300\n",
            "cost = 0.10563439327351615\n",
            "Epoch: 90/300\n",
            "cost = 0.10467464141247569\n",
            "Epoch: 91/300\n",
            "cost = 0.10372986140361395\n",
            "Epoch: 92/300\n",
            "cost = 0.10279699835447415\n",
            "Epoch: 93/300\n",
            "cost = 0.1018688891348441\n",
            "Epoch: 94/300\n",
            "cost = 0.10095611589541317\n",
            "Epoch: 95/300\n",
            "cost = 0.10006425969067845\n",
            "Epoch: 96/300\n",
            "cost = 0.09918054137084897\n",
            "Epoch: 97/300\n",
            "cost = 0.09830905856229966\n",
            "Epoch: 98/300\n",
            "cost = 0.09744960022069295\n",
            "Epoch: 99/300\n",
            "cost = 0.09660039487307583\n",
            "Epoch: 100/300\n",
            "cost = 0.0957634369105657\n",
            "Epoch: 101/300\n",
            "cost = 0.09493704359353583\n",
            "Epoch: 102/300\n",
            "cost = 0.09411786629829182\n",
            "Epoch: 103/300\n",
            "cost = 0.09330793562113397\n",
            "Epoch: 104/300\n",
            "cost = 0.09251380213109803\n",
            "Epoch: 105/300\n",
            "cost = 0.09173170345047024\n",
            "Epoch: 106/300\n",
            "cost = 0.09095473405674732\n",
            "Epoch: 107/300\n",
            "cost = 0.09018945379097096\n",
            "Epoch: 108/300\n",
            "cost = 0.08943501675429831\n",
            "Epoch: 109/300\n",
            "cost = 0.08868839274265902\n",
            "Epoch: 110/300\n",
            "cost = 0.0879507483653691\n",
            "Epoch: 111/300\n",
            "cost = 0.08722191875234848\n",
            "Epoch: 112/300\n",
            "cost = 0.08650328908560957\n",
            "Epoch: 113/300\n",
            "cost = 0.08578924637827896\n",
            "Epoch: 114/300\n",
            "cost = 0.08508191711100872\n",
            "Epoch: 115/300\n",
            "cost = 0.08438206523498452\n",
            "Epoch: 116/300\n",
            "cost = 0.08368808848783585\n",
            "Epoch: 117/300\n",
            "cost = 0.08300075340538025\n",
            "Epoch: 118/300\n",
            "cost = 0.08231990385327526\n",
            "Epoch: 119/300\n",
            "cost = 0.08164313560568622\n",
            "Epoch: 120/300\n",
            "cost = 0.08097300546182543\n",
            "Epoch: 121/300\n",
            "cost = 0.08030950768845366\n",
            "Epoch: 122/300\n",
            "cost = 0.0796533935041822\n",
            "Epoch: 123/300\n",
            "cost = 0.07900490896203502\n",
            "Epoch: 124/300\n",
            "cost = 0.07836132559080931\n",
            "Epoch: 125/300\n",
            "cost = 0.07772298786248158\n",
            "Epoch: 126/300\n",
            "cost = 0.0770917428444545\n",
            "Epoch: 127/300\n",
            "cost = 0.07647018934083356\n",
            "Epoch: 128/300\n",
            "cost = 0.07585351282213532\n",
            "Epoch: 129/300\n",
            "cost = 0.07524099686308652\n",
            "Epoch: 130/300\n",
            "cost = 0.07463426204368452\n",
            "Epoch: 131/300\n",
            "cost = 0.07403165496852976\n",
            "Epoch: 132/300\n",
            "cost = 0.07343273385263349\n",
            "Epoch: 133/300\n",
            "cost = 0.07282079815809882\n",
            "Epoch: 134/300\n",
            "cost = 0.07221010446842413\n",
            "Epoch: 135/300\n",
            "cost = 0.07161701109339988\n",
            "Epoch: 136/300\n",
            "cost = 0.07103675400718198\n",
            "Epoch: 137/300\n",
            "cost = 0.07046274449884583\n",
            "Epoch: 138/300\n",
            "cost = 0.06989584975962604\n",
            "Epoch: 139/300\n",
            "cost = 0.06933438145273793\n",
            "Epoch: 140/300\n",
            "cost = 0.06877683932672407\n",
            "Epoch: 141/300\n",
            "cost = 0.0682232261585711\n",
            "Epoch: 142/300\n",
            "cost = 0.06767474829331253\n",
            "Epoch: 143/300\n",
            "cost = 0.06713122352614175\n",
            "Epoch: 144/300\n",
            "cost = 0.06659334114324147\n",
            "Epoch: 145/300\n",
            "cost = 0.06606041263175895\n",
            "Epoch: 146/300\n",
            "cost = 0.06553146183519008\n",
            "Epoch: 147/300\n",
            "cost = 0.06500671764785723\n",
            "Epoch: 148/300\n",
            "cost = 0.0644873333833644\n",
            "Epoch: 149/300\n",
            "cost = 0.06397182609960611\n",
            "Epoch: 150/300\n",
            "cost = 0.06346239475461703\n",
            "Epoch: 151/300\n",
            "cost = 0.06295846613416396\n",
            "Epoch: 152/300\n",
            "cost = 0.062460434490051356\n",
            "Epoch: 153/300\n",
            "cost = 0.06196610633274884\n",
            "Epoch: 154/300\n",
            "cost = 0.061477065066993186\n",
            "Epoch: 155/300\n",
            "cost = 0.06099153695119637\n",
            "Epoch: 156/300\n",
            "cost = 0.060510100453431026\n",
            "Epoch: 157/300\n",
            "cost = 0.06003049727508456\n",
            "Epoch: 158/300\n",
            "cost = 0.059554351319476985\n",
            "Epoch: 159/300\n",
            "cost = 0.05908064263256476\n",
            "Epoch: 160/300\n",
            "cost = 0.05861029095618156\n",
            "Epoch: 161/300\n",
            "cost = 0.05814538958527176\n",
            "Epoch: 162/300\n",
            "cost = 0.05768317105932174\n",
            "Epoch: 163/300\n",
            "cost = 0.0572238038523589\n",
            "Epoch: 164/300\n",
            "cost = 0.05676888839202516\n",
            "Epoch: 165/300\n",
            "cost = 0.056319019622438064\n",
            "Epoch: 166/300\n",
            "cost = 0.05587225569109976\n",
            "Epoch: 167/300\n",
            "cost = 0.05542840283947928\n",
            "Epoch: 168/300\n",
            "cost = 0.05498838986083655\n",
            "Epoch: 169/300\n",
            "cost = 0.054552356781086796\n",
            "Epoch: 170/300\n",
            "cost = 0.05412101232328114\n",
            "Epoch: 171/300\n",
            "cost = 0.05369230309620307\n",
            "Epoch: 172/300\n",
            "cost = 0.0532683997100027\n",
            "Epoch: 173/300\n",
            "cost = 0.052849219785032965\n",
            "Epoch: 174/300\n",
            "cost = 0.05243331386484914\n",
            "Epoch: 175/300\n",
            "cost = 0.052021241430373\n",
            "Epoch: 176/300\n",
            "cost = 0.05161367423384598\n",
            "Epoch: 177/300\n",
            "cost = 0.05120975773664462\n",
            "Epoch: 178/300\n",
            "cost = 0.050808829887618485\n",
            "Epoch: 179/300\n",
            "cost = 0.05041046253679128\n",
            "Epoch: 180/300\n",
            "cost = 0.050015316221001326\n",
            "Epoch: 181/300\n",
            "cost = 0.04962284388363239\n",
            "Epoch: 182/300\n",
            "cost = 0.04923432678463031\n",
            "Epoch: 183/300\n",
            "cost = 0.04884889817906226\n",
            "Epoch: 184/300\n",
            "cost = 0.04846654705086236\n",
            "Epoch: 185/300\n",
            "cost = 0.048088200691475076\n",
            "Epoch: 186/300\n",
            "cost = 0.04771491612567087\n",
            "Epoch: 187/300\n",
            "cost = 0.04734591151203666\n",
            "Epoch: 188/300\n",
            "cost = 0.04697990365867918\n",
            "Epoch: 189/300\n",
            "cost = 0.04661680714696588\n",
            "Epoch: 190/300\n",
            "cost = 0.04625697854569297\n",
            "Epoch: 191/300\n",
            "cost = 0.04590075512728278\n",
            "Epoch: 192/300\n",
            "cost = 0.04554814194890635\n",
            "Epoch: 193/300\n",
            "cost = 0.045199674141309584\n",
            "Epoch: 194/300\n",
            "cost = 0.04485406556317785\n",
            "Epoch: 195/300\n",
            "cost = 0.044511438604023595\n",
            "Epoch: 196/300\n",
            "cost = 0.044171379697480376\n",
            "Epoch: 197/300\n",
            "cost = 0.04383581487728405\n",
            "Epoch: 198/300\n",
            "cost = 0.043503970034450404\n",
            "Epoch: 199/300\n",
            "cost = 0.0431749252353182\n",
            "Epoch: 200/300\n",
            "cost = 0.04284969027085487\n",
            "Epoch: 201/300\n",
            "cost = 0.04252720398031672\n",
            "Epoch: 202/300\n",
            "cost = 0.04220622960728047\n",
            "Epoch: 203/300\n",
            "cost = 0.041889200732899944\n",
            "Epoch: 204/300\n",
            "cost = 0.04157493612529414\n",
            "Epoch: 205/300\n",
            "cost = 0.041263265425312765\n",
            "Epoch: 206/300\n",
            "cost = 0.04095436613510347\n",
            "Epoch: 207/300\n",
            "cost = 0.040647574245065515\n",
            "Epoch: 208/300\n",
            "cost = 0.04034324941991727\n",
            "Epoch: 209/300\n",
            "cost = 0.04004156514837429\n",
            "Epoch: 210/300\n",
            "cost = 0.039741122278967186\n",
            "Epoch: 211/300\n",
            "cost = 0.03944238255161785\n",
            "Epoch: 212/300\n",
            "cost = 0.03914508238825024\n",
            "Epoch: 213/300\n",
            "cost = 0.038850191853391516\n",
            "Epoch: 214/300\n",
            "cost = 0.03855670765961285\n",
            "Epoch: 215/300\n",
            "cost = 0.03826587869252981\n",
            "Epoch: 216/300\n",
            "cost = 0.03797701729023522\n",
            "Epoch: 217/300\n",
            "cost = 0.03769141760527169\n",
            "Epoch: 218/300\n",
            "cost = 0.037408039593580605\n",
            "Epoch: 219/300\n",
            "cost = 0.03712712527676021\n",
            "Epoch: 220/300\n",
            "cost = 0.03684757407818333\n",
            "Epoch: 221/300\n",
            "cost = 0.03657079089459663\n",
            "Epoch: 222/300\n",
            "cost = 0.03629713702913129\n",
            "Epoch: 223/300\n",
            "cost = 0.03602717163007849\n",
            "Epoch: 224/300\n",
            "cost = 0.03575892752463701\n",
            "Epoch: 225/300\n",
            "cost = 0.035491676738978184\n",
            "Epoch: 226/300\n",
            "cost = 0.03522594813010306\n",
            "Epoch: 227/300\n",
            "cost = 0.03496233869123652\n",
            "Epoch: 228/300\n",
            "cost = 0.03470120711828008\n",
            "Epoch: 229/300\n",
            "cost = 0.03444181627439853\n",
            "Epoch: 230/300\n",
            "cost = 0.03418384208415182\n",
            "Epoch: 231/300\n",
            "cost = 0.03392663998423191\n",
            "Epoch: 232/300\n",
            "cost = 0.033670884219425136\n",
            "Epoch: 233/300\n",
            "cost = 0.03341786859174839\n",
            "Epoch: 234/300\n",
            "cost = 0.03316632436835352\n",
            "Epoch: 235/300\n",
            "cost = 0.03291655878022296\n",
            "Epoch: 236/300\n",
            "cost = 0.032668253966532175\n",
            "Epoch: 237/300\n",
            "cost = 0.03242193210116752\n",
            "Epoch: 238/300\n",
            "cost = 0.03217756765206739\n",
            "Epoch: 239/300\n",
            "cost = 0.03193530459878848\n",
            "Epoch: 240/300\n",
            "cost = 0.03169585672556397\n",
            "Epoch: 241/300\n",
            "cost = 0.03145785607392737\n",
            "Epoch: 242/300\n",
            "cost = 0.031221356263897986\n",
            "Epoch: 243/300\n",
            "cost = 0.03098806589310943\n",
            "Epoch: 244/300\n",
            "cost = 0.030757050054561138\n",
            "Epoch: 245/300\n",
            "cost = 0.030525920588674347\n",
            "Epoch: 246/300\n",
            "cost = 0.0302968989425614\n",
            "Epoch: 247/300\n",
            "cost = 0.0300696602902222\n",
            "Epoch: 248/300\n",
            "cost = 0.029844119576301776\n",
            "Epoch: 249/300\n",
            "cost = 0.029621272650843022\n",
            "Epoch: 250/300\n",
            "cost = 0.029398726119410988\n",
            "Epoch: 251/300\n",
            "cost = 0.029178436493776307\n",
            "Epoch: 252/300\n",
            "cost = 0.028960547939694572\n",
            "Epoch: 253/300\n",
            "cost = 0.028743282364980225\n",
            "Epoch: 254/300\n",
            "cost = 0.028526964154827066\n",
            "Epoch: 255/300\n",
            "cost = 0.028312843101451726\n",
            "Epoch: 256/300\n",
            "cost = 0.028100461728595826\n",
            "Epoch: 257/300\n",
            "cost = 0.0278889069160814\n",
            "Epoch: 258/300\n",
            "cost = 0.027679494370594433\n",
            "Epoch: 259/300\n",
            "cost = 0.027473064501242577\n",
            "Epoch: 260/300\n",
            "cost = 0.0272672212715411\n",
            "Epoch: 261/300\n",
            "cost = 0.02706371132311109\n",
            "Epoch: 262/300\n",
            "cost = 0.02685975147633218\n",
            "Epoch: 263/300\n",
            "cost = 0.026658560633416675\n",
            "Epoch: 264/300\n",
            "cost = 0.02645855544995766\n",
            "Epoch: 265/300\n",
            "cost = 0.02626040542891082\n",
            "Epoch: 266/300\n",
            "cost = 0.026065287212078295\n",
            "Epoch: 267/300\n",
            "cost = 0.025870978138441712\n",
            "Epoch: 268/300\n",
            "cost = 0.02567748695187762\n",
            "Epoch: 269/300\n",
            "cost = 0.025486245152896544\n",
            "Epoch: 270/300\n",
            "cost = 0.025296056583072074\n",
            "Epoch: 271/300\n",
            "cost = 0.025107825523666725\n",
            "Epoch: 272/300\n",
            "cost = 0.02492106119701782\n",
            "Epoch: 273/300\n",
            "cost = 0.02473702502773641\n",
            "Epoch: 274/300\n",
            "cost = 0.024554640309593173\n",
            "Epoch: 275/300\n",
            "cost = 0.02437255426610718\n",
            "Epoch: 276/300\n",
            "cost = 0.024193337313135777\n",
            "Epoch: 277/300\n",
            "cost = 0.024015072000102746\n",
            "Epoch: 278/300\n",
            "cost = 0.023837244961323605\n",
            "Epoch: 279/300\n",
            "cost = 0.023660204103313362\n",
            "Epoch: 280/300\n",
            "cost = 0.023483782097633136\n",
            "Epoch: 281/300\n",
            "cost = 0.023309386722290246\n",
            "Epoch: 282/300\n",
            "cost = 0.02313515158188561\n",
            "Epoch: 283/300\n",
            "cost = 0.02296191294493702\n",
            "Epoch: 284/300\n",
            "cost = 0.02278909866889714\n",
            "Epoch: 285/300\n",
            "cost = 0.022616632004095565\n",
            "Epoch: 286/300\n",
            "cost = 0.022445638744771124\n",
            "Epoch: 287/300\n",
            "cost = 0.02227603855154499\n",
            "Epoch: 288/300\n",
            "cost = 0.022107376036358446\n",
            "Epoch: 289/300\n",
            "cost = 0.021940478722186133\n",
            "Epoch: 290/300\n",
            "cost = 0.021774849828304164\n",
            "Epoch: 291/300\n",
            "cost = 0.02161007724589791\n",
            "Epoch: 292/300\n",
            "cost = 0.021447334135080976\n",
            "Epoch: 293/300\n",
            "cost = 0.021286261917634913\n",
            "Epoch: 294/300\n",
            "cost = 0.02112691718182418\n",
            "Epoch: 295/300\n",
            "cost = 0.020968823107494174\n",
            "Epoch: 296/300\n",
            "cost = 0.02081214600834703\n",
            "Epoch: 297/300\n",
            "cost = 0.02065766172190873\n",
            "Epoch: 298/300\n",
            "cost = 0.020504166101376328\n",
            "Epoch: 299/300\n",
            "cost = 0.020352421441103184\n",
            "Epoch: 300/300\n",
            "cost = 0.020202367720905133\n",
            "\n",
            "Training Model_3:\n",
            "\n",
            "Epoch: 1/300\n",
            "cost = 3.0656196297751035\n",
            "Epoch: 2/300\n",
            "cost = 2.0262911654812803\n",
            "Epoch: 3/300\n",
            "cost = 1.6505307841795058\n",
            "Epoch: 4/300\n",
            "cost = 1.4529407276284367\n",
            "Epoch: 5/300\n",
            "cost = 1.1533948417768307\n",
            "Epoch: 6/300\n",
            "cost = 1.006006645947344\n",
            "Epoch: 7/300\n",
            "cost = 0.9792112334873144\n",
            "Epoch: 8/300\n",
            "cost = 0.7566198526247803\n",
            "Epoch: 9/300\n",
            "cost = 0.8538116118876995\n",
            "Epoch: 10/300\n",
            "cost = 0.6847269925890735\n",
            "Epoch: 11/300\n",
            "cost = 0.6318243081657459\n",
            "Epoch: 12/300\n",
            "cost = 0.6088221048400354\n",
            "Epoch: 13/300\n",
            "cost = 0.5475444702664555\n",
            "Epoch: 14/300\n",
            "cost = 0.5301429207226723\n",
            "Epoch: 15/300\n",
            "cost = 0.4706436311161708\n",
            "Epoch: 16/300\n",
            "cost = 0.5039770188513767\n",
            "Epoch: 17/300\n",
            "cost = 0.4214434489393248\n",
            "Epoch: 18/300\n",
            "cost = 0.42432844168381717\n",
            "Epoch: 19/300\n",
            "cost = 0.4079263205051017\n",
            "Epoch: 20/300\n",
            "cost = 0.38293330967425887\n",
            "Epoch: 21/300\n",
            "cost = 0.3805538085729027\n",
            "Epoch: 22/300\n",
            "cost = 0.35437993853484717\n",
            "Epoch: 23/300\n",
            "cost = 0.33118896053972663\n",
            "Epoch: 24/300\n",
            "cost = 0.32185589986251023\n",
            "Epoch: 25/300\n",
            "cost = 0.31207733343600735\n",
            "Epoch: 26/300\n",
            "cost = 0.3010594115472449\n",
            "Epoch: 27/300\n",
            "cost = 0.28775362142412303\n",
            "Epoch: 28/300\n",
            "cost = 0.278608163811768\n",
            "Epoch: 29/300\n",
            "cost = 0.2737045597026513\n",
            "Epoch: 30/300\n",
            "cost = 0.26399473302859444\n",
            "Epoch: 31/300\n",
            "cost = 0.2513242821694927\n",
            "Epoch: 32/300\n",
            "cost = 0.24408509306759726\n",
            "Epoch: 33/300\n",
            "cost = 0.24198267738475326\n",
            "Epoch: 34/300\n",
            "cost = 0.2374045531954185\n",
            "Epoch: 35/300\n",
            "cost = 0.22863996082144988\n",
            "Epoch: 36/300\n",
            "cost = 0.22156573831260415\n",
            "Epoch: 37/300\n",
            "cost = 0.21682659204627183\n",
            "Epoch: 38/300\n",
            "cost = 0.21198395471917322\n",
            "Epoch: 39/300\n",
            "cost = 0.2066076601234741\n",
            "Epoch: 40/300\n",
            "cost = 0.20139540559896493\n",
            "Epoch: 41/300\n",
            "cost = 0.1970089415723131\n",
            "Epoch: 42/300\n",
            "cost = 0.1933887892486244\n",
            "Epoch: 43/300\n",
            "cost = 0.18963541702204914\n",
            "Epoch: 44/300\n",
            "cost = 0.185624280369209\n",
            "Epoch: 45/300\n",
            "cost = 0.18159153226696031\n",
            "Epoch: 46/300\n",
            "cost = 0.17773905557648817\n",
            "Epoch: 47/300\n",
            "cost = 0.17425985408157027\n",
            "Epoch: 48/300\n",
            "cost = 0.1713578168543357\n",
            "Epoch: 49/300\n",
            "cost = 0.16846524657010192\n",
            "Epoch: 50/300\n",
            "cost = 0.165062615266728\n",
            "Epoch: 51/300\n",
            "cost = 0.16206251175764055\n",
            "Epoch: 52/300\n",
            "cost = 0.1597331704007144\n",
            "Epoch: 53/300\n",
            "cost = 0.15719047733585048\n",
            "Epoch: 54/300\n",
            "cost = 0.1542477579587772\n",
            "Epoch: 55/300\n",
            "cost = 0.15168179261836837\n",
            "Epoch: 56/300\n",
            "cost = 0.14963179880573987\n",
            "Epoch: 57/300\n",
            "cost = 0.14745585639607361\n",
            "Epoch: 58/300\n",
            "cost = 0.14513217180424692\n",
            "Epoch: 59/300\n",
            "cost = 0.14303932670793285\n",
            "Epoch: 60/300\n",
            "cost = 0.14107670837769906\n",
            "Epoch: 61/300\n",
            "cost = 0.13908265380316256\n",
            "Epoch: 62/300\n",
            "cost = 0.13711559788981179\n",
            "Epoch: 63/300\n",
            "cost = 0.13521064575384292\n",
            "Epoch: 64/300\n",
            "cost = 0.13338715131310924\n",
            "Epoch: 65/300\n",
            "cost = 0.1316753214875808\n",
            "Epoch: 66/300\n",
            "cost = 0.13001487286762203\n",
            "Epoch: 67/300\n",
            "cost = 0.12831761809879424\n",
            "Epoch: 68/300\n",
            "cost = 0.12665879508890804\n",
            "Epoch: 69/300\n",
            "cost = 0.12512192658580515\n",
            "Epoch: 70/300\n",
            "cost = 0.12362240388246426\n",
            "Epoch: 71/300\n",
            "cost = 0.12212734459352985\n",
            "Epoch: 72/300\n",
            "cost = 0.1206665371238795\n",
            "Epoch: 73/300\n",
            "cost = 0.119209835653144\n",
            "Epoch: 74/300\n",
            "cost = 0.11774706799834157\n",
            "Epoch: 75/300\n",
            "cost = 0.1163460666207241\n",
            "Epoch: 76/300\n",
            "cost = 0.11499179747118564\n",
            "Epoch: 77/300\n",
            "cost = 0.11363886089059765\n",
            "Epoch: 78/300\n",
            "cost = 0.11233148578597127\n",
            "Epoch: 79/300\n",
            "cost = 0.1110739888412947\n",
            "Epoch: 80/300\n",
            "cost = 0.10983935152861739\n",
            "Epoch: 81/300\n",
            "cost = 0.10862085853658573\n",
            "Epoch: 82/300\n",
            "cost = 0.10741559604846404\n",
            "Epoch: 83/300\n",
            "cost = 0.10622135280794646\n",
            "Epoch: 84/300\n",
            "cost = 0.10504060604003095\n",
            "Epoch: 85/300\n",
            "cost = 0.10387620837686853\n",
            "Epoch: 86/300\n",
            "cost = 0.10271270237293174\n",
            "Epoch: 87/300\n",
            "cost = 0.10156969214236415\n",
            "Epoch: 88/300\n",
            "cost = 0.10047179726695699\n",
            "Epoch: 89/300\n",
            "cost = 0.09938097194974299\n",
            "Epoch: 90/300\n",
            "cost = 0.0982961642182491\n",
            "Epoch: 91/300\n",
            "cost = 0.09723684309764\n",
            "Epoch: 92/300\n",
            "cost = 0.0961984908649169\n",
            "Epoch: 93/300\n",
            "cost = 0.09516549064583275\n",
            "Epoch: 94/300\n",
            "cost = 0.09414208861161132\n",
            "Epoch: 95/300\n",
            "cost = 0.09313873593294791\n",
            "Epoch: 96/300\n",
            "cost = 0.09215963595777234\n",
            "Epoch: 97/300\n",
            "cost = 0.09119545250943385\n",
            "Epoch: 98/300\n",
            "cost = 0.09024446286541159\n",
            "Epoch: 99/300\n",
            "cost = 0.08930928884299189\n",
            "Epoch: 100/300\n",
            "cost = 0.08838505212941393\n",
            "Epoch: 101/300\n",
            "cost = 0.08747746242734629\n",
            "Epoch: 102/300\n",
            "cost = 0.08658455570537109\n",
            "Epoch: 103/300\n",
            "cost = 0.0857029964897127\n",
            "Epoch: 104/300\n",
            "cost = 0.08483130955426903\n",
            "Epoch: 105/300\n",
            "cost = 0.08396239202069437\n",
            "Epoch: 106/300\n",
            "cost = 0.08310351319150727\n",
            "Epoch: 107/300\n",
            "cost = 0.08225646834010718\n",
            "Epoch: 108/300\n",
            "cost = 0.08141808263795491\n",
            "Epoch: 109/300\n",
            "cost = 0.08058781242989986\n",
            "Epoch: 110/300\n",
            "cost = 0.07976372389643077\n",
            "Epoch: 111/300\n",
            "cost = 0.07894793337461072\n",
            "Epoch: 112/300\n",
            "cost = 0.07814266885923805\n",
            "Epoch: 113/300\n",
            "cost = 0.07734310006738895\n",
            "Epoch: 114/300\n",
            "cost = 0.07654960141779196\n",
            "Epoch: 115/300\n",
            "cost = 0.07576336960165962\n",
            "Epoch: 116/300\n",
            "cost = 0.0749850842117655\n",
            "Epoch: 117/300\n",
            "cost = 0.07420984849816262\n",
            "Epoch: 118/300\n",
            "cost = 0.07344337296788636\n",
            "Epoch: 119/300\n",
            "cost = 0.0726854695800773\n",
            "Epoch: 120/300\n",
            "cost = 0.07193925843440409\n",
            "Epoch: 121/300\n",
            "cost = 0.07120416234747091\n",
            "Epoch: 122/300\n",
            "cost = 0.07047612664978799\n",
            "Epoch: 123/300\n",
            "cost = 0.06975215397103757\n",
            "Epoch: 124/300\n",
            "cost = 0.0690357451994848\n",
            "Epoch: 125/300\n",
            "cost = 0.06833280015633496\n",
            "Epoch: 126/300\n",
            "cost = 0.06763917122939411\n",
            "Epoch: 127/300\n",
            "cost = 0.06695098435157365\n",
            "Epoch: 128/300\n",
            "cost = 0.06627281861807949\n",
            "Epoch: 129/300\n",
            "cost = 0.06560440075386108\n",
            "Epoch: 130/300\n",
            "cost = 0.0649452936047452\n",
            "Epoch: 131/300\n",
            "cost = 0.0642960570915171\n",
            "Epoch: 132/300\n",
            "cost = 0.06365369407842955\n",
            "Epoch: 133/300\n",
            "cost = 0.06302174369876068\n",
            "Epoch: 134/300\n",
            "cost = 0.062397971166024815\n",
            "Epoch: 135/300\n",
            "cost = 0.061777556181861384\n",
            "Epoch: 136/300\n",
            "cost = 0.06116315605882138\n",
            "Epoch: 137/300\n",
            "cost = 0.06055961792636331\n",
            "Epoch: 138/300\n",
            "cost = 0.05996331372252038\n",
            "Epoch: 139/300\n",
            "cost = 0.059375353440202165\n",
            "Epoch: 140/300\n",
            "cost = 0.058793896456265905\n",
            "Epoch: 141/300\n",
            "cost = 0.058221447758745035\n",
            "Epoch: 142/300\n",
            "cost = 0.057655155469791344\n",
            "Epoch: 143/300\n",
            "cost = 0.05709318456189585\n",
            "Epoch: 144/300\n",
            "cost = 0.05653751986904396\n",
            "Epoch: 145/300\n",
            "cost = 0.05598946988631905\n",
            "Epoch: 146/300\n",
            "cost = 0.055448266464603164\n",
            "Epoch: 147/300\n",
            "cost = 0.054911954231606906\n",
            "Epoch: 148/300\n",
            "cost = 0.05438115919099084\n",
            "Epoch: 149/300\n",
            "cost = 0.05385623801263901\n",
            "Epoch: 150/300\n",
            "cost = 0.05333745466137677\n",
            "Epoch: 151/300\n",
            "cost = 0.05282575076453016\n",
            "Epoch: 152/300\n",
            "cost = 0.0523202757571183\n",
            "Epoch: 153/300\n",
            "cost = 0.05182151396106427\n",
            "Epoch: 154/300\n",
            "cost = 0.05132894408139967\n",
            "Epoch: 155/300\n",
            "cost = 0.05084350068355511\n",
            "Epoch: 156/300\n",
            "cost = 0.05035925121628758\n",
            "Epoch: 157/300\n",
            "cost = 0.04987753888945132\n",
            "Epoch: 158/300\n",
            "cost = 0.049402259522255236\n",
            "Epoch: 159/300\n",
            "cost = 0.04893027918529158\n",
            "Epoch: 160/300\n",
            "cost = 0.048464516455773585\n",
            "Epoch: 161/300\n",
            "cost = 0.04800174247002171\n",
            "Epoch: 162/300\n",
            "cost = 0.047539932804809976\n",
            "Epoch: 163/300\n",
            "cost = 0.04708495106107697\n",
            "Epoch: 164/300\n",
            "cost = 0.04663436041481582\n",
            "Epoch: 165/300\n",
            "cost = 0.04618709403908135\n",
            "Epoch: 166/300\n",
            "cost = 0.04574499033221386\n",
            "Epoch: 167/300\n",
            "cost = 0.045304077820107695\n",
            "Epoch: 168/300\n",
            "cost = 0.044870427736899185\n",
            "Epoch: 169/300\n",
            "cost = 0.044439555422046605\n",
            "Epoch: 170/300\n",
            "cost = 0.04401267679012616\n",
            "Epoch: 171/300\n",
            "cost = 0.04359119879948798\n",
            "Epoch: 172/300\n",
            "cost = 0.04317400135803248\n",
            "Epoch: 173/300\n",
            "cost = 0.0427608757785747\n",
            "Epoch: 174/300\n",
            "cost = 0.04235151048312813\n",
            "Epoch: 175/300\n",
            "cost = 0.04194379915063377\n",
            "Epoch: 176/300\n",
            "cost = 0.041540206936466664\n",
            "Epoch: 177/300\n",
            "cost = 0.04114171711535014\n",
            "Epoch: 178/300\n",
            "cost = 0.040747561935922966\n",
            "Epoch: 179/300\n",
            "cost = 0.04035545920862904\n",
            "Epoch: 180/300\n",
            "cost = 0.03996978044821321\n",
            "Epoch: 181/300\n",
            "cost = 0.039588661982778814\n",
            "Epoch: 182/300\n",
            "cost = 0.039211266150714554\n",
            "Epoch: 183/300\n",
            "cost = 0.038840398583746\n",
            "Epoch: 184/300\n",
            "cost = 0.03847343333474083\n",
            "Epoch: 185/300\n",
            "cost = 0.03810932239304665\n",
            "Epoch: 186/300\n",
            "cost = 0.037747660617236674\n",
            "Epoch: 187/300\n",
            "cost = 0.03738617066359026\n",
            "Epoch: 188/300\n",
            "cost = 0.03702888202949839\n",
            "Epoch: 189/300\n",
            "cost = 0.0366737063610098\n",
            "Epoch: 190/300\n",
            "cost = 0.03632004146377983\n",
            "Epoch: 191/300\n",
            "cost = 0.035967530307134725\n",
            "Epoch: 192/300\n",
            "cost = 0.035617622259350376\n",
            "Epoch: 193/300\n",
            "cost = 0.03526854422777656\n",
            "Epoch: 194/300\n",
            "cost = 0.03492685367763098\n",
            "Epoch: 195/300\n",
            "cost = 0.03458720220039445\n",
            "Epoch: 196/300\n",
            "cost = 0.034250489706806546\n",
            "Epoch: 197/300\n",
            "cost = 0.03391523583580898\n",
            "Epoch: 198/300\n",
            "cost = 0.03358158809547157\n",
            "Epoch: 199/300\n",
            "cost = 0.03325214864901573\n",
            "Epoch: 200/300\n",
            "cost = 0.03292839009393739\n",
            "Epoch: 201/300\n",
            "cost = 0.03260934153201763\n",
            "Epoch: 202/300\n",
            "cost = 0.03229269689265176\n",
            "Epoch: 203/300\n",
            "cost = 0.03198061855899019\n",
            "Epoch: 204/300\n",
            "cost = 0.031671152068348335\n",
            "Epoch: 205/300\n",
            "cost = 0.031364435196639166\n",
            "Epoch: 206/300\n",
            "cost = 0.03106197150481896\n",
            "Epoch: 207/300\n",
            "cost = 0.03076051257613089\n",
            "Epoch: 208/300\n",
            "cost = 0.030462743117497026\n",
            "Epoch: 209/300\n",
            "cost = 0.03016879358532239\n",
            "Epoch: 210/300\n",
            "cost = 0.029877296419638766\n",
            "Epoch: 211/300\n",
            "cost = 0.029587440497279648\n",
            "Epoch: 212/300\n",
            "cost = 0.02930030209801504\n",
            "Epoch: 213/300\n",
            "cost = 0.02901705797565698\n",
            "Epoch: 214/300\n",
            "cost = 0.028737456688730963\n",
            "Epoch: 215/300\n",
            "cost = 0.028460627588453358\n",
            "Epoch: 216/300\n",
            "cost = 0.02818689500905038\n",
            "Epoch: 217/300\n",
            "cost = 0.02791660341457909\n",
            "Epoch: 218/300\n",
            "cost = 0.027650231713135253\n",
            "Epoch: 219/300\n",
            "cost = 0.02738528119696167\n",
            "Epoch: 220/300\n",
            "cost = 0.027123573616179272\n",
            "Epoch: 221/300\n",
            "cost = 0.026864195190638054\n",
            "Epoch: 222/300\n",
            "cost = 0.02660759751804848\n",
            "Epoch: 223/300\n",
            "cost = 0.026352771925703507\n",
            "Epoch: 224/300\n",
            "cost = 0.026102240430547416\n",
            "Epoch: 225/300\n",
            "cost = 0.02585204939040566\n",
            "Epoch: 226/300\n",
            "cost = 0.025604768123976926\n",
            "Epoch: 227/300\n",
            "cost = 0.025358811886439583\n",
            "Epoch: 228/300\n",
            "cost = 0.025113531199549795\n",
            "Epoch: 229/300\n",
            "cost = 0.024872433847982593\n",
            "Epoch: 230/300\n",
            "cost = 0.024633395703714808\n",
            "Epoch: 231/300\n",
            "cost = 0.02439521820499193\n",
            "Epoch: 232/300\n",
            "cost = 0.024157729835080858\n",
            "Epoch: 233/300\n",
            "cost = 0.02392261321026498\n",
            "Epoch: 234/300\n",
            "cost = 0.02368966883343428\n",
            "Epoch: 235/300\n",
            "cost = 0.0234597749351559\n",
            "Epoch: 236/300\n",
            "cost = 0.02323148357403515\n",
            "Epoch: 237/300\n",
            "cost = 0.023007122980211486\n",
            "Epoch: 238/300\n",
            "cost = 0.02278570122918143\n",
            "Epoch: 239/300\n",
            "cost = 0.022567537651335796\n",
            "Epoch: 240/300\n",
            "cost = 0.022352733781640332\n",
            "Epoch: 241/300\n",
            "cost = 0.022140892925293816\n",
            "Epoch: 242/300\n",
            "cost = 0.021930859462442512\n",
            "Epoch: 243/300\n",
            "cost = 0.02172287957952197\n",
            "Epoch: 244/300\n",
            "cost = 0.021516786038573807\n",
            "Epoch: 245/300\n",
            "cost = 0.02131436566661226\n",
            "Epoch: 246/300\n",
            "cost = 0.02111296394533084\n",
            "Epoch: 247/300\n",
            "cost = 0.02091383074947183\n",
            "Epoch: 248/300\n",
            "cost = 0.02071472379938087\n",
            "Epoch: 249/300\n",
            "cost = 0.02051903396022119\n",
            "Epoch: 250/300\n",
            "cost = 0.020325444940481142\n",
            "Epoch: 251/300\n",
            "cost = 0.0201333213752909\n",
            "Epoch: 252/300\n",
            "cost = 0.01994318567636979\n",
            "Epoch: 253/300\n",
            "cost = 0.019754914043391948\n",
            "Epoch: 254/300\n",
            "cost = 0.01957069607095847\n",
            "Epoch: 255/300\n",
            "cost = 0.019389003384798664\n",
            "Epoch: 256/300\n",
            "cost = 0.019208490035421803\n",
            "Epoch: 257/300\n",
            "cost = 0.019029863937443325\n",
            "Epoch: 258/300\n",
            "cost = 0.018853288778305038\n",
            "Epoch: 259/300\n",
            "cost = 0.01867812157142384\n",
            "Epoch: 260/300\n",
            "cost = 0.01850560041010857\n",
            "Epoch: 261/300\n",
            "cost = 0.018333715882042245\n",
            "Epoch: 262/300\n",
            "cost = 0.018164143591003455\n",
            "Epoch: 263/300\n",
            "cost = 0.017997852225344724\n",
            "Epoch: 264/300\n",
            "cost = 0.017832968208257482\n",
            "Epoch: 265/300\n",
            "cost = 0.01767133861641249\n",
            "Epoch: 266/300\n",
            "cost = 0.01751181658623543\n",
            "Epoch: 267/300\n",
            "cost = 0.01735310544626624\n",
            "Epoch: 268/300\n",
            "cost = 0.01719671422132539\n",
            "Epoch: 269/300\n",
            "cost = 0.01704113627110883\n",
            "Epoch: 270/300\n",
            "cost = 0.01688836858896539\n",
            "Epoch: 271/300\n",
            "cost = 0.016736996780243634\n",
            "Epoch: 272/300\n",
            "cost = 0.01658710070503105\n",
            "Epoch: 273/300\n",
            "cost = 0.016437998707396748\n",
            "Epoch: 274/300\n",
            "cost = 0.01628988634953\n",
            "Epoch: 275/300\n",
            "cost = 0.016142031202355703\n",
            "Epoch: 276/300\n",
            "cost = 0.0159973521501947\n",
            "Epoch: 277/300\n",
            "cost = 0.015853213431619315\n",
            "Epoch: 278/300\n",
            "cost = 0.01571184454097367\n",
            "Epoch: 279/300\n",
            "cost = 0.015571734657757158\n",
            "Epoch: 280/300\n",
            "cost = 0.015432165814486832\n",
            "Epoch: 281/300\n",
            "cost = 0.015294153753075643\n",
            "Epoch: 282/300\n",
            "cost = 0.015155973416718193\n",
            "Epoch: 283/300\n",
            "cost = 0.015020157478372528\n",
            "Epoch: 284/300\n",
            "cost = 0.014884765581576587\n",
            "Epoch: 285/300\n",
            "cost = 0.014751350558421108\n",
            "Epoch: 286/300\n",
            "cost = 0.01461861811176232\n",
            "Epoch: 287/300\n",
            "cost = 0.014489052239611597\n",
            "Epoch: 288/300\n",
            "cost = 0.01436061952192629\n",
            "Epoch: 289/300\n",
            "cost = 0.014233460662398327\n",
            "Epoch: 290/300\n",
            "cost = 0.014107332420890387\n",
            "Epoch: 291/300\n",
            "cost = 0.013982149659487035\n",
            "Epoch: 292/300\n",
            "cost = 0.013859066862814134\n",
            "Epoch: 293/300\n",
            "cost = 0.013737058444696734\n",
            "Epoch: 294/300\n",
            "cost = 0.013615432453860809\n",
            "Epoch: 295/300\n",
            "cost = 0.01349725299623537\n",
            "Epoch: 296/300\n",
            "cost = 0.013380053501764678\n",
            "Epoch: 297/300\n",
            "cost = 0.013264122275596976\n",
            "Epoch: 298/300\n",
            "cost = 0.013149847167013557\n",
            "Epoch: 299/300\n",
            "cost = 0.013037902211705407\n",
            "Epoch: 300/300\n",
            "cost = 0.012926986359430966\n"
          ]
        }
      ],
      "source": [
        "# List to store all the models\n",
        "models = [model1, model2, model3]\n",
        "\n",
        "# Train each custom model and track its progress\n",
        "for i, model in enumerate(models):\n",
        "    print(f\"\\nTraining Model_{i+1}:\\n\")\n",
        "    model.fit(X_train_scaled, Y_train, epochs=300, alpha=3) # Train the model for 300 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "tCLV1iHzqgcx",
        "outputId": "eadfad30-eb71-4cda-e6bd-a10fa062181c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x400 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot iteration vs cost (loss) for each model\n",
        "_, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "    cost_hist = np.array(model.cost_history)  # Retrieve cost history\n",
        "    ax[i].plot(cost_hist[:, 0], cost_hist[:, 1], label=f\"Model_{i+1}\")  # Plot iteration vs cost\n",
        "    ax[i].set_title(\"Iteration vs Cost\")\n",
        "    ax[i].set_xlabel(\"Iteration\")\n",
        "    ax[i].set_ylabel(\"Cost\")\n",
        "    ax[i].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9n25OIo6ZGW"
      },
      "source": [
        "All three models show a rapid decrease in **cost** during the initial iterations, indicating effective training, and reflecting successful minimization of the **loss function**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb5WNCn3qgc0",
        "outputId": "d2f6a78c-ccc1-41b0-deee-fcb402c9bee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model_1 Train accuracy: 0.9828862973760933, Model_1 Val accuracy: 0.9425170068027211\n",
            "Model_1 Train f1 score: 0.9828815968903449, Model_1 Val f1 score: 0.9424468448808451\n",
            "\n",
            "Model_2 Train accuracy: 0.9964139941690963, Model_2 Val accuracy: 0.9471428571428572\n",
            "Model_2 Train f1 score: 0.9964144374132472, Model_2 Val f1 score: 0.9471401861860138\n",
            "\n",
            "Model_3 Train accuracy: 0.9974927113702624, Model_3 Val accuracy: 0.9523809523809523\n",
            "Model_3 Train f1 score: 0.9974930447777863, Model_3 Val f1 score: 0.9523713628226722\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Evaluate accuracy and F1 score on train and validation sets for each model\n",
        "for i, model in enumerate(models):\n",
        "    # Make predictions on the training and validation sets\n",
        "    Y_hat_train = np.argmax(model.predict(X_train_scaled), axis=1, keepdims=True)\n",
        "    Y_hat_val = np.argmax(model.predict(X_val_scaled), axis=1, keepdims=True)\n",
        "\n",
        "    # Compute accuracy\n",
        "    train_accuracy = accuracy_score(Y_train, Y_hat_train)\n",
        "    val_accuracy = accuracy_score(Y_val, Y_hat_val)\n",
        "    print(f\"Model_{i+1} Train accuracy: {train_accuracy}, Model_{i+1} Val accuracy: {val_accuracy}\")\n",
        "\n",
        "    # Compute F1 score\n",
        "    train_f1 = f1_score(Y_train, Y_hat_train, average=\"weighted\")\n",
        "    val_f1 = f1_score(Y_val, Y_hat_val, average=\"weighted\")\n",
        "    print(f\"Model_{i+1} Train f1 score: {train_f1}, Model_{i+1} Val f1 score: {val_f1}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfKTjZFN6ZGY"
      },
      "source": [
        "Among the evaluated neural network models, **Model_3** emerges as the best performer. It achieves an impressive **training accuracy** of **99.75%** and a **validation accuracy** of **95.24%**. Additionally, it records a **training F1 score** of **99.75%** and a **validation F1 score** of **95.24%**. **Model_2** also performs well with a **training accuracy** of **99.64%** and a **validation accuracy** of **94.71%**, while **Model_1**, despite having a simpler architecture, achieves a respectable **training accuracy** of **98.29%** and a **validation accuracy** of **94.25%**. While all models demonstrate strong performance, **Model_3**'s superior metrics make it the most effective choice for our task. Now it's time to test the optimal model on test set, but for intuition we will evaluate all models on the testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s-clGW0qgc4",
        "outputId": "3f8fa801-7201-4dd7-a886-d86c28fefdab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model_1 Test accuracy: 0.9421904761904762\n",
            "Model_1 Test f1 score: 0.942104661768477\n",
            "\n",
            "Model_2 Test accuracy: 0.9473809523809524\n",
            "Model_2 Test f1 score: 0.9473496303216566\n",
            "\n",
            "Model_3 Test accuracy: 0.949952380952381\n",
            "Model_3 Test f1 score: 0.9499062705300603\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the custom models on the test set\n",
        "for i, model in enumerate(models):\n",
        "    # Make predictions on the test set\n",
        "    Y_hat_test = np.argmax(model.predict(X_test_scaled), axis=1, keepdims=True)\n",
        "\n",
        "    # Compute accuracy\n",
        "    test_accuracy = accuracy_score(Y_test, Y_hat_test)\n",
        "    print(f\"Model_{i+1} Test accuracy: {test_accuracy}\")\n",
        "\n",
        "    # Compute F1 score\n",
        "    test_f1 = f1_score(Y_test, Y_hat_test, average=\"weighted\")\n",
        "    print(f\"Model_{i+1} Test f1 score: {test_f1}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xKNRRqV6ZGa"
      },
      "source": [
        "The testing results highlight the effectiveness of **Model_3** as the optimal choice. With a **test accuracy** of **95.00%** and a **test F1 score** of **95.00%**, **Model_3** outperforms the other models, showcasing its superior capabilities during the testing phase. **Model_2** follows closely with a **test accuracy** of **94.74%** and a **test F1 score** of **94.74%**. Meanwhile, **Model_1** achieves a **test accuracy** of **94.22%** and a **test F1 score** of **94.21%**. While all models demonstrate strong performance, **Model_3**'s metrics confirm it as the most effective model for the given dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "pf8eUWQDqgc6",
        "outputId": "35fd4525-cc75-423c-fa6a-81e81784e458"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">31,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,230</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">620</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)                  │          \u001b[38;5;34m31,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │           \u001b[38;5;34m1,230\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m620\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,460</span> (130.70 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,460\u001b[0m (130.70 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,460</span> (130.70 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,460\u001b[0m (130.70 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the optimal model architecture using TensorFlow based on the evaluation of custom models\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),  # Input layer with the feature size\n",
        "    tf.keras.layers.Dense(40, activation=\"relu\"),  # First hidden layer\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),  # Second hidden layer\n",
        "    tf.keras.layers.Dense(20, activation=\"relu\"),  # Third hidden layer\n",
        "    tf.keras.layers.Dense(10, activation=\"linear\")  # Output layer with linear activation (logits)\n",
        "])\n",
        "\n",
        "# Compile the TensorFlow model with Adam optimizer and SparseCategoricalCrossentropy loss\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # Specify softmax in loss\n",
        ")\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8gnBMTvqgc8",
        "outputId": "d65fded3-bab2-49a6-a98d-93ec2ae7217b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 1.0957\n",
            "Epoch 2/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2184\n",
            "Epoch 3/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1403\n",
            "Epoch 4/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1035\n",
            "Epoch 5/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0883\n",
            "Epoch 6/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0687\n",
            "Epoch 7/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0632\n",
            "Epoch 8/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0566\n",
            "Epoch 9/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0481\n",
            "Epoch 10/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0456\n",
            "Epoch 11/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0459\n",
            "Epoch 12/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0390\n",
            "Epoch 13/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0388\n",
            "Epoch 14/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0309\n",
            "Epoch 15/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0334\n",
            "Epoch 16/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0786\n",
            "Epoch 17/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0541\n",
            "Epoch 18/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0484\n",
            "Epoch 19/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0303\n",
            "Epoch 20/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0229\n",
            "Epoch 21/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0210\n",
            "Epoch 22/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0144\n",
            "Epoch 23/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0145\n",
            "Epoch 24/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116\n",
            "Epoch 25/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095\n",
            "Epoch 26/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0216\n",
            "Epoch 27/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0209\n",
            "Epoch 28/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0199\n",
            "Epoch 29/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0206\n",
            "Epoch 30/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0234\n",
            "Epoch 31/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0222\n",
            "Epoch 32/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0229\n",
            "Epoch 33/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0190\n",
            "Epoch 34/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0292\n",
            "Epoch 35/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0289\n",
            "Epoch 36/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0337\n",
            "Epoch 37/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361\n",
            "Epoch 38/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0219\n",
            "Epoch 39/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0239\n",
            "Epoch 40/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0092\n",
            "Epoch 41/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0093\n",
            "Epoch 42/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049\n",
            "Epoch 43/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040\n",
            "Epoch 44/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023\n",
            "Epoch 45/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024\n",
            "Epoch 46/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018\n",
            "Epoch 47/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012\n",
            "Epoch 48/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1218e-04\n",
            "Epoch 49/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6577e-04\n",
            "Epoch 50/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9419e-04\n",
            "Epoch 51/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0581e-04\n",
            "Epoch 52/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9752e-05\n",
            "Epoch 53/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3641e-04\n",
            "Epoch 54/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8489e-05\n",
            "Epoch 55/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3711e-05\n",
            "Epoch 56/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5958e-05\n",
            "Epoch 57/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8132e-05\n",
            "Epoch 58/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4163e-05\n",
            "Epoch 59/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4863e-05\n",
            "Epoch 60/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2465e-05\n",
            "Epoch 61/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.7179e-05\n",
            "Epoch 62/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8486e-05\n",
            "Epoch 63/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1289e-05\n",
            "Epoch 64/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8867e-05\n",
            "Epoch 65/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6351e-05\n",
            "Epoch 66/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5316e-05\n",
            "Epoch 67/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5818e-05\n",
            "Epoch 68/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6493e-05\n",
            "Epoch 69/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2527e-05\n",
            "Epoch 70/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2736e-05\n",
            "Epoch 71/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1872e-05\n",
            "Epoch 72/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5309e-05\n",
            "Epoch 73/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4946e-05\n",
            "Epoch 74/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8713e-05\n",
            "Epoch 75/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2128e-05\n",
            "Epoch 76/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3257e-05\n",
            "Epoch 77/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0296e-05\n",
            "Epoch 78/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1122e-05\n",
            "Epoch 79/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6766e-05\n",
            "Epoch 80/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8261e-05\n",
            "Epoch 81/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8913e-05\n",
            "Epoch 82/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6731e-05\n",
            "Epoch 83/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6126e-05\n",
            "Epoch 84/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6827e-05\n",
            "Epoch 85/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7409e-05\n",
            "Epoch 86/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5892e-05\n",
            "Epoch 87/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6614e-05\n",
            "Epoch 88/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6077e-05\n",
            "Epoch 89/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6297e-05\n",
            "Epoch 90/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4426e-05\n",
            "Epoch 91/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2765e-05\n",
            "Epoch 92/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2659e-05\n",
            "Epoch 93/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3075e-05\n",
            "Epoch 94/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3839e-05\n",
            "Epoch 95/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2346e-05\n",
            "Epoch 96/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3405e-05\n",
            "Epoch 97/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4640e-05\n",
            "Epoch 98/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0817e-05\n",
            "Epoch 99/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1120e-05\n",
            "Epoch 100/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0689e-05\n",
            "Epoch 101/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0812e-05\n",
            "Epoch 102/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1161e-05\n",
            "Epoch 103/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0909e-05\n",
            "Epoch 104/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5061e-06\n",
            "Epoch 105/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0263e-06\n",
            "Epoch 106/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.2925e-06\n",
            "Epoch 107/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.9003e-06\n",
            "Epoch 108/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.4720e-06\n",
            "Epoch 109/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.3656e-06\n",
            "Epoch 110/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8497e-06\n",
            "Epoch 111/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1340e-06\n",
            "Epoch 112/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6800e-06\n",
            "Epoch 113/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2917e-06\n",
            "Epoch 114/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7964e-06\n",
            "Epoch 115/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9760e-06\n",
            "Epoch 116/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1828e-06\n",
            "Epoch 117/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1253e-06\n",
            "Epoch 118/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9574e-06\n",
            "Epoch 119/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6848e-06\n",
            "Epoch 120/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9322e-06\n",
            "Epoch 121/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3074e-06\n",
            "Epoch 122/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8998e-06\n",
            "Epoch 123/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6856e-06\n",
            "Epoch 124/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5740e-06\n",
            "Epoch 125/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0172e-06\n",
            "Epoch 126/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4893e-06\n",
            "Epoch 127/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8584e-06\n",
            "Epoch 128/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1012e-06\n",
            "Epoch 129/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8190e-06\n",
            "Epoch 130/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7777e-06\n",
            "Epoch 131/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8148e-06\n",
            "Epoch 132/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7488e-06\n",
            "Epoch 133/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4818e-06\n",
            "Epoch 134/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1665e-06\n",
            "Epoch 135/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3468e-06\n",
            "Epoch 136/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0806e-06\n",
            "Epoch 137/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9952e-06\n",
            "Epoch 138/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2647e-06\n",
            "Epoch 139/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5276e-06\n",
            "Epoch 140/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1663e-06\n",
            "Epoch 141/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9482e-06\n",
            "Epoch 142/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7851e-06\n",
            "Epoch 143/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6014e-06\n",
            "Epoch 144/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0583e-06\n",
            "Epoch 145/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4689e-06\n",
            "Epoch 146/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2651e-06\n",
            "Epoch 147/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4393e-06\n",
            "Epoch 148/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3621e-06\n",
            "Epoch 149/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1278e-06\n",
            "Epoch 150/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2276e-06\n",
            "Epoch 151/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7013e-06\n",
            "Epoch 152/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9060e-06\n",
            "Epoch 153/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0539e-06\n",
            "Epoch 154/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9050e-06\n",
            "Epoch 155/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7077e-06\n",
            "Epoch 156/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6584e-06\n",
            "Epoch 157/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2413e-06\n",
            "Epoch 158/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1517e-06\n",
            "Epoch 159/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3267e-06\n",
            "Epoch 160/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7264e-06\n",
            "Epoch 161/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5364e-06\n",
            "Epoch 162/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3643e-06\n",
            "Epoch 163/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4454e-06\n",
            "Epoch 164/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6670e-06\n",
            "Epoch 165/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2462e-06\n",
            "Epoch 166/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0918e-06\n",
            "Epoch 167/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1800e-06\n",
            "Epoch 168/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2422e-06\n",
            "Epoch 169/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0376e-06\n",
            "Epoch 170/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9618e-06\n",
            "Epoch 171/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1848e-06\n",
            "Epoch 172/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2045e-06\n",
            "Epoch 173/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8928e-06\n",
            "Epoch 174/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9144e-06\n",
            "Epoch 175/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0145e-06\n",
            "Epoch 176/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9390e-06\n",
            "Epoch 177/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6447e-06\n",
            "Epoch 178/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7822e-06\n",
            "Epoch 179/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7399e-06\n",
            "Epoch 180/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6454e-06\n",
            "Epoch 181/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4732e-06\n",
            "Epoch 182/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5476e-06\n",
            "Epoch 183/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4753e-06\n",
            "Epoch 184/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5632e-06\n",
            "Epoch 185/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4346e-06\n",
            "Epoch 186/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5076e-06\n",
            "Epoch 187/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4468e-06\n",
            "Epoch 188/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4777e-06\n",
            "Epoch 189/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5461e-06\n",
            "Epoch 190/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4844e-06\n",
            "Epoch 191/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3759e-06\n",
            "Epoch 192/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2497e-06\n",
            "Epoch 193/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2648e-06\n",
            "Epoch 194/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2201e-06\n",
            "Epoch 195/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4089e-06\n",
            "Epoch 196/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0520e-06\n",
            "Epoch 197/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2022e-06\n",
            "Epoch 198/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0331e-06\n",
            "Epoch 199/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1327e-06\n",
            "Epoch 200/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1904e-06\n",
            "Epoch 201/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1985e-06\n",
            "Epoch 202/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0875e-06\n",
            "Epoch 203/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0576e-06\n",
            "Epoch 204/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1757e-06\n",
            "Epoch 205/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7107e-07\n",
            "Epoch 206/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5366e-07\n",
            "Epoch 207/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7872e-07\n",
            "Epoch 208/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1362e-07\n",
            "Epoch 209/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6324e-07\n",
            "Epoch 210/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2108e-07\n",
            "Epoch 211/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7119e-07\n",
            "Epoch 212/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8466e-07\n",
            "Epoch 213/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6101e-07\n",
            "Epoch 214/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4292e-07\n",
            "Epoch 215/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7479e-07\n",
            "Epoch 216/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5764e-07\n",
            "Epoch 217/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0614e-07\n",
            "Epoch 218/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5068e-07\n",
            "Epoch 219/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7262e-07\n",
            "Epoch 220/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5554e-07\n",
            "Epoch 221/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7575e-07\n",
            "Epoch 222/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8560e-07\n",
            "Epoch 223/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6704e-07\n",
            "Epoch 224/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3211e-07\n",
            "Epoch 225/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8709e-07\n",
            "Epoch 226/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7676e-07\n",
            "Epoch 227/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1806e-07\n",
            "Epoch 228/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3733e-07\n",
            "Epoch 229/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0571e-07\n",
            "Epoch 230/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8320e-07\n",
            "Epoch 231/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8307e-07\n",
            "Epoch 232/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4215e-07\n",
            "Epoch 233/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5993e-07\n",
            "Epoch 234/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0002e-07\n",
            "Epoch 235/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4162e-07\n",
            "Epoch 236/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4771e-07\n",
            "Epoch 237/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1850e-07\n",
            "Epoch 238/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3078e-07\n",
            "Epoch 239/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7979e-07\n",
            "Epoch 240/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0904e-07\n",
            "Epoch 241/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8006e-07\n",
            "Epoch 242/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1249e-07\n",
            "Epoch 243/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8711e-07\n",
            "Epoch 244/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9836e-07\n",
            "Epoch 245/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4570e-07\n",
            "Epoch 246/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4333e-07\n",
            "Epoch 247/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6354e-07\n",
            "Epoch 248/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2148e-07\n",
            "Epoch 249/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2287e-07\n",
            "Epoch 250/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1143e-07\n",
            "Epoch 251/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4704e-07\n",
            "Epoch 252/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5460e-07\n",
            "Epoch 253/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6076e-07\n",
            "Epoch 254/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5171e-07\n",
            "Epoch 255/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8187e-07\n",
            "Epoch 256/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6712e-07\n",
            "Epoch 257/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0080e-07\n",
            "Epoch 258/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0855e-07\n",
            "Epoch 259/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1690e-07\n",
            "Epoch 260/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7418e-07\n",
            "Epoch 261/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3157e-07\n",
            "Epoch 262/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2255e-07\n",
            "Epoch 263/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1385e-07\n",
            "Epoch 264/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9271e-07\n",
            "Epoch 265/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0720e-07\n",
            "Epoch 266/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9525e-07\n",
            "Epoch 267/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2876e-07\n",
            "Epoch 268/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1417e-07\n",
            "Epoch 269/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7317e-07\n",
            "Epoch 270/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4978e-07\n",
            "Epoch 271/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8127e-07\n",
            "Epoch 272/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6325e-07\n",
            "Epoch 273/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5279e-07\n",
            "Epoch 274/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7566e-07\n",
            "Epoch 275/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4291e-07\n",
            "Epoch 276/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5596e-07\n",
            "Epoch 277/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3675e-07\n",
            "Epoch 278/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3957e-07\n",
            "Epoch 279/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1766e-07\n",
            "Epoch 280/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2358e-07\n",
            "Epoch 281/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0920e-07\n",
            "Epoch 282/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1257e-07\n",
            "Epoch 283/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4434e-07\n",
            "Epoch 284/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3534e-07\n",
            "Epoch 285/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2970e-07\n",
            "Epoch 286/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0752e-07\n",
            "Epoch 287/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0474e-07\n",
            "Epoch 288/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8056e-07\n",
            "Epoch 289/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9117e-07\n",
            "Epoch 290/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1080e-07\n",
            "Epoch 291/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0438e-07\n",
            "Epoch 292/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8677e-07\n",
            "Epoch 293/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7858e-07\n",
            "Epoch 294/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7591e-07\n",
            "Epoch 295/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8047e-07\n",
            "Epoch 296/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6929e-07\n",
            "Epoch 297/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6145e-07\n",
            "Epoch 298/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7087e-07\n",
            "Epoch 299/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4172e-07\n",
            "Epoch 300/300\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6899e-07\n"
          ]
        }
      ],
      "source": [
        "# Train the TensorFlow model\n",
        "history = model.fit(X_train_scaled, Y_train,\n",
        "                    epochs=300,  # Train for 300 epochs\n",
        "                    batch_size=1000)  # Use a batch size of 1000 samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "mygJ08-Pqgc9",
        "outputId": "694353fa-66ff-4ccc-e78a-5f7d7bfc9a1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7aad3218b0a0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get the loss values from the training process\n",
        "train_loss = history.history[\"loss\"]  # Training loss for each epoch\n",
        "\n",
        "# Plot iteration (epochs) vs cost (loss)\n",
        "plt.plot(range(1, len(train_loss) + 1), train_loss, label=\"Training Loss\")\n",
        "plt.title(\"Iterations vs. Cost (Loss)\")\n",
        "plt.xlabel(\"Iterations (Epochs)\")\n",
        "plt.ylabel(\"Cost (Loss)\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHoN1fFWN_w5"
      },
      "source": [
        "The **TensorFlow model's training loss** shows a sharp decline in the initial epochs, indicating efficient learning early on. By around **50 epochs**, the loss stabilizes close to zero, demonstrating that the model has effectively minimized the error and converged to an optimal solution during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hg09ZDcqgc-",
        "outputId": "a73aec10-bd70-470d-e381-8e656400f1eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "Train accuracy: 1.0\n",
            "Train f1 score: 1.0\n",
            "\n",
            "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Val accuracy: 0.9636734693877551\n",
            "Val f1 score: 0.9636737067049463\n",
            "\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Test accuracy: 0.9628095238095238\n",
            "Test f1 score: 0.9628326626197176\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a list of datasets for predictions (train, validation, test)\n",
        "all_data = [(\"Train\", X_train_scaled, Y_train), (\"Val\", X_val_scaled, Y_val), (\"Test\", X_test_scaled, Y_test)]\n",
        "\n",
        "# Predict and evaluate accuracy and F1 score for each dataset (train, validation, test)\n",
        "for data in all_data:\n",
        "    # Predict using the model (logits will be returned due to linear activation)\n",
        "    logits = model.predict(data[1])\n",
        "\n",
        "    # Apply softmax to convert logits to probabilities\n",
        "    probabilities = tf.nn.softmax(logits, axis=1)\n",
        "\n",
        "    # Use argmax to get the predicted class labels (highest probability)\n",
        "    predicted_classes = np.argmax(probabilities, axis=1).reshape(-1, 1)\n",
        "\n",
        "    # Compute accuracy for each dataset\n",
        "    accuracy = accuracy_score(predicted_classes, data[2])\n",
        "    print(f\"{data[0]} accuracy: {accuracy}\")\n",
        "\n",
        "    # Compute F1 score for each dataset\n",
        "    f1 = f1_score(predicted_classes, data[2], average=\"weighted\")\n",
        "    print(f\"{data[0]} f1 score: {f1}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIaQqcbm6ZGf"
      },
      "source": [
        "In comparing the results of **Model_3** with the TensorFlow model, we observe that both models deliver strong performance, but with notable differences. **Model_3** achieves a **train accuracy** of **99.75%** and a **train F1 score** of **99.75%**. Its **validation accuracy** stands at **95.24%** with a **validation F1 score** of **95.24%**, while the **test accuracy** is **95.00%** and the **test F1 score** is **95.00%**. In contrast, the TensorFlow model boasts a perfect **train accuracy** and **train F1 score** of **100%**. Having **validation accuracy** at **96.37%** and **test accuracy** at **96.28%** with corresponding F1 scores. Although **Model_3** performs well, the TensorFlow model shows slightly better metrics, highlighting its effectiveness across all stages of evaluation.\n",
        "\n",
        "With these insights, we conclude our project successfully. Both models have demonstrated their effectiveness, but the TensorFlow model provides a marginal edge in overall performance."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
